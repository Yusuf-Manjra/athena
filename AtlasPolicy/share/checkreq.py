#!/usr/bin/env python
# $Id: checkreq.py,v 1.0 2014/03/12 18:00:00 hans Exp $
#
# Hans von der Schmitt, 12-Mar-2014
#
# This is the python equivalent of old checkreq.sh, developed further
#
#----------------------------------------------------------------------------------------------------------------------------------
#
#  checkreq.py
#  -----------
#  author of original shell script: Jakob Nielsen, maintained by Hans von der Schmitt
#  converted to Python by: Steve LLoyd, Hans von der Schmitt
#
#  This script which checks consistency of the requirements file of a package with 
#  the header and implementation files of that package in the following sense:
#  The set of packages appearing in use statements must be the same as the
#  set of packages from #include statements and linkopts statements. Optionally
#  distinguishes private and public sections of the requirements, and restricts
#  to publicly visible header files.
#  Does some extra checking in addition to that.
#
#  The script also checks if inter-project dependencies are correct. This check 
#  covers static dependencies stated in #include statements and use statements, 
#  and run-time dependencies generated by include/import statements in python files.
#
#-------------------------------------------------------------------------------
#
#  Update history from November 2008 on:
#
#  20081128 hvds - converted to python
#                - removed some history on the way
#  20090108 hvds - first usable python version
#  20090112 hvds - fix in do_write for option -plw
#  20090115 hvds - skip use for most externals (apart from exceptions which have 
#                  distinctive include dir names or include file names)
#  20090119 hvds - streamlined the priv/pub crosscheck algorithm
#                - taken do_modif out of do_write, and changed to retain 
#                  "apparently not needed" use stmts: only add missing use and do
#                  shifts between private and public
#  20090122 hvds - fixed bug in do_modif (in case requirements end without \n)
#                  also comment out original use names in do_modif
#                - retain a copy of original requirements for better checking
#                - change severity of "need public instead of private" from 3 to 2
#                - updated usage printout
#                - added list of trigger packages (only linkage dependency) to 
#                  those to be ignored in use stmts
#  20090123 hvds - fixed regexp bug in do_modif (commented too many use stmts)
#                - fixed bug which showed a too long list of files including a 
#                  given package
#                - (disabled for now:) added check if use xxxPolicy is first use 
#                  statement
#  20090124 hvds - refined selection of directories for sources/headers
#                - consider only 1st use stmt for a packet to copy its extensions 
#                  (like -no_imports) to generated use stmts in do_modif
#                - changed insertion point for use stmts in do_modif to have all
#                  extra use stmts directly after 1st original use stmt
#                - treat some packages in TDAQ_COMMON as if they had use statements
#  20090127 hvds - corrected do_modif - missed the public / end_public in some cases
#  20090131 hvds - parsing of c++ files now also interprets #ifdefs etc. using cpp
#                  switches defined in requirements. Comment handling also added
#                - bug in detection of ROOT include files corrected
#  20090204 hvds - force use AtlasPolicy to public in do_modif
#  20090211 hvds - default is now to do NO versions cache. New option -x for extended
#                  versions checking (which was the old default)
#                - replaced os.walk with loop over os.listdir to speed cache generation
#  20090306 hvds - new option -a switches off public/private crosschecks (inverse of -p)
#                - added project AtlasHLT
#                - allow absolute release path for release ident in option -r, then 
#                  don't apply standard distribution area path
#                - ignore ".." if used in #includes in package name position
#                - severity of "need public instead of private" changed to 3
#  20090319 hvds - generate more complete diagnostics for missing use: list all reasons
#                  why a package needs a use statement, instead of just one
#                - disregard source/header files in ../root, in addition to ../doc etc.
#                - disregard, for public, header file for the current package appearing 
#                  in apply_pattern lcgdict ... headerfiles="<file>" 
#  20090321 hvds - updated translation tables and ROOT version
#  20090428 hvds - added uuid to notrans list
#  20090520 hvds - updated to latest LCG versions for ROOT, CORAL, COOL, POOL
#  20090630 hvds - made path to ROOT more dynamic
#  20090730 hvds - translations for Tdaq/Tdaq common packages, but excluded translation
#                  for CTPfragment, MuCalDecode, EventStorage, Xm, eformat, ers, ipc, circ, 
#                  omniORB4, and non-directories incl df_allocator
#                - removed bug which crashed checkreq for use stmts without version field
#  20090812 hvds - added .hxx to extensions considered for header files
#  20090827 hvds - fixed bug in pattern for poolcnv filepaths (found only last one if several)
#  20090907 hvds - don't count poolcnv filepaths as public package references
#  20091107 hvds - disregard #includes which use relative paths
#  20091122 hvds - added OpenGL to the list of package names to be ignored (system header on Mac)
#                - accept "#if defined()" as preprocessor stmt, in addition to #ifdef
#  20091201 hvds - added Graf to translations to AtlasROOT
#  20100104 hvds - LCG_Interfaces packages excluded from checking
#  20100526 hvds - updated translations generated automatically
#                - translate include LWH to Rivet
#                - ignore AtlasFortranPolicy (use and include)
#  20100707 hvds - error if AtlasPolicy is private where it should be public
#  20101122 hvds - added two more translations for external generators (SHERPA, ATOOLS -> Sherpa)
#                - lowered severity to 2 for problems in package statements
#  20110202 hvds - updated translations to LCG config 60
#  20110301 hvds - new option -y/--python for checking python includes against use stmts.
#                - limited the search for py files to files under ../python/ by default.
#  20110318 hvds - translations updated to LCG60b (COOL, CORAL, POOL, ROOT), to tdaq-03-00-01,
#                  and to tdaq-common-01-17-01
#                - made option -p the default
#  20110401 hvds - included GAUDI in list of recognised projects to avoid crash
#                - for package versions in use stmts, deprecated all but *, v*, <pack>*, <pack>-*
#  20110420 hvds - warning in case of changes to important cppflags, distinguishing public/private
#                - changed wording of warning in case of public instead of private use
#                - big speedup of cache creation (takes now 20 sec)
#  20110426 hvds - excluded GaudiPolicy from checking. Expect GaudiPolicy (instead AtlasPolicy) for
#                  GAUDI packages.
#                - Expect AtlasHLTPolicy or AtlasPolicy or TDAQPolicy for AtlasHLT packages.
#  20110531 hvds - removed AtlasP1HLT from list of projects.
#                - improved check for cache completeness (all accessible projects must be covered).
#                - allowed again version formats <pack>-nn*, <pack>-nn-* (as *, v*, <pack>*, <pack>-*)
#                  but <pack>-nn-nn*, <pack>-nn-nn-* get warnings (few cases).
#  20110606 hvds - reverted the above: version fields *, v*, <pack>*, <pack>-* are allowed. All others 
#                  produce warnings.
#  20110607 hvds - removed bug in do_cpp comment detection
#  20110902 hvds - added HLTtdaq to list of implied use stmts (treatlikeuse)
#  20111004 hvds - translated Mt2 to AtlasmT2, and added some translations from inc2pac to lib2pac
#  20111205 hvds - POOLCore etc. not translated to AtlasPOOL for packages Database/APR/...
#  20111216 hvds - bugfix: translated cppunit (instead of CppUnit) to AtlasCppUnit
#  20111221 hvds - use stmts for apply_pattern APRTest_run and APR_test considered
#  20120116 hvds - force GaudiInterface to public scope (in do_checks)
#  20120124 hvds - output (commented) primary dependencies for dep-checkreq.py (prepared, not yet enabled)
#  20120221 hvds - Photos translated to Photospp, and updated all translations
#  20120227 hvds - reverted the GaudiInterface change (marks #!#)
#  20120316 hvds - included AtlasCommonPolicy in list of policy packages (to be skipped)
#                - (not yet) warning if use or #include of CBNT (will be phased out)
#  20120326 hvds - quick filling of project:container:package-version list (need not be "cache"d anymore)
#                - added traslations frontier_client -> Frontier_Client, boost/python.hpp -> AtlasPython
#                - new option -i/--ignore=<level> to write a WARNING/ERROR only if severity > <level>
#                - extra translation: ignore #include PDF
#  20120401 hvds - added project ManaCore, and a safeguard against undefined project
#  20120521 hvds - Tauola translated to Tauolapp
#  20120626 hvds - consider use TestTools in package POOLCore despite no_auto_imports
#                - updated translations to HLTtdaq
#                - for the --writeuse option, added missing end_private at end of private block
#  20120829 hvds - absorb use stms for PyJobTransforms, -Core, -Misc (with treatlikepac)
#  20121010 hvds - added some diagnostics if access to root/includes fails, delayed gerneration of 
#                  root includes
#                - lowered severity of debug macros to 2
#  20121112 obreshko - translate EvtGenExternal to EvtGen
#  20121115 seuster - prepend 'CHECKREQ--->' string to any regular output
#  20121119 hvds - extended to all regular output, as well as to the other exit()s
#  20121213 hvds - skip checking of container packages where <version> = <pack>Release-<pack>-nn-nn...
#  20130110 hvds - corrections to py file checking
#  20130302 hvds - translate external LHAPDF to Lhapdf
#  20130410 hvds - translate new external Eigen to AtlasEigen
#  20130415 hvds - refined check for double compilation
#  20130718 hvds - completed resolving of tagged cmt macros in case of -Dxxx definitions
#  20130917 hvds - take care of non-existing but referenced <package>Dict_gen.h file: warn with severity 2
#                - fix crash on any non-existing referenced file: warn instead with severity 2
#                - absorb use stms for AtlasROOT specifically (often comes in via Reflex dict)
#                - bug corrected in setting up versions cache: avoid duplicates from later in $CMTPATH,
#                  which had caused fake bad project dependencies
#                - also, reduced severity for bad project dependencies to 2 (bad runtime remains 1)
#  20130918 hvds - skip project dependency and versions checks for patch releases
#                - simplified/corrected determination of project etc. using cmt show projects 
#                  (thanks to Emil)
#  20130924 hvds - added translation RunControl -> HLTtdaq
#                - also updated xxxDict.h translations according to contents of 18.0.0
#  20130926 hvds - added check for modification of other package's linkopts (in public or private part 
#                  of requirements, both only severity 1 for now)
#  20131015 hvds - filtered out lowercase and _ dirs in apply_pattern poolcnv (like in other translations)
#                - public/private now ignored for GaudiInterface #include and use (see change of 20120116)
#  20131022 hvds - added three Java packages to those to skip
#  20131023 hvds - reverted most translations for HLTtdaq, HLTtdaqcommon; only kept RunControl -> HLTtdaq
#                  (20130924 changed accordingly)
#                - imply use stmts for #includes from <package>Dict_gen.h file
#                - consider extensions .hh, .hxx, .hpp (in addition to .h and .icc) for publicly visible files
#  20131029 hvds - added xAOD to notrans list
#  20140226 hvds - public/private ignored for YODA #include and use, like for GaudiInterface (see 20131015)
#                - added YODA to externals to interpret in use stmts
#  20140306 hvds - translate hltinterface to HLTtdaqcommon or HLTtdaq, depending on available use statements,
#                  and translate TTCInfo to nil
#                - removed HLTtdaq from list of implied use stmts (treatlikeuse) (see 20110902)
#                - updated translations to HLTtdaqcommon and HLTtdaq (see 20131023)
#  20140312 hvds - improved diagnostic for HLTtdaq/HLTtdaqcommon
#  20140819 mnowak - added use_if and use_unless parsing
#  20140902 sss  - Handle Gaudi/ include directory provided by GaudiPluginSvc.
#  20140910 sss  - Skip checks for Hephaestus.
#  20140930 obreshko - replaced ManaCore with AthAnalysisBase
#  20141110 sss  - Handle Pythia8Plugins directory from Pythia8.
#  20141205 sss  - Allow changing linkopts for other libraries built in
#                  the package.
#
###################################################################################################################################

from sys import exit, argv
from os import path, remove, walk, chdir, chmod, listdir, popen
from shutil import copyfile
from re import compile
from getopt import getopt, GetoptError
from datetime import datetime
import re

class checker:
  def __init__(self):

# checkreq version string
    self.ckrvers="checkreq-v140312"

# some patterns used in several places
    self.patTroot=compile("^T[A-Z][a-zA-Z0-9]*\.h")   # (potential) ROOT header file name
    self.patLund=compile("[a-z_]")                    # string with lowercase or underscore

# flag if root include directory already scanned
    self.rootdone=False

# options - are modified in __main__ according to cmd-line options
    self.o_detail=False
    self.o_ignore=0
    self.o_nicos=""
    self.o_local=False
    self.o_needcache=True #False
    self.o_public="both" #!!# "all"
    self.o_python=False
    self.o_pydirs=["scripts"] #["python"]
    self.o_writeuse=False
    self.o_relident=""

# prepare checker-global variables (some could come from the environmt but set constant for now)
    self.distarea="/afs/cern.ch/atlas/software/builds/"

    self.workpath=path.abspath(".")

# list of projects
    self.projmap={"AtlasCore":None, "AtlasConditions":None, "AtlasEvent":None, "AtlasReconstruction":None, \
      "AtlasTrigger":None, "AtlasAnalysis":None, "AtlasSimulation":None, "AtlasOffline":None, \
      "AtlasProduction":None, "DetCommon":None, "AtlasHLT":None, "GAUDI":None, "AthAnalysisBase":None}
# per project, setup list of non-accessible projects
    self.projmap["AtlasProduction"]=[]
    self.projmap["AtlasOffline"]=["AtlasProduction"]
    self.projmap["AtlasSimulation"]=["AtlasReconstruction", "AtlasTrigger", "AtlasAnalysis", "AtlasOffline"]
    self.projmap["AtlasAnalysis"]=["AtlasSimulation", "AtlasOffline"]
    self.projmap["AtlasTrigger"]=["AtlasAnalysis"]+self.projmap["AtlasAnalysis"]
    self.projmap["AtlasReconstruction"]=["AtlasTrigger"]+self.projmap["AtlasTrigger"]
    self.projmap["AtlasEvent"]=["AtlasReconstruction"]+self.projmap["AtlasReconstruction"]
    self.projmap["AtlasConditions"]=["AtlasEvent"]+self.projmap["AtlasEvent"]
    self.projmap["AtlasCore"]=["AtlasConditions"]+self.projmap["AtlasConditions"]
    self.projmap["DetCommon"]=self.projmap["AtlasCore"]
    self.projmap["AtlasHLT"]=[]
    self.projmap["GAUDI"]=[]
    self.projmap["AthAnalysisBase"]=[]

    self.policy1 = ["AtlasPolicy", "GaudiPolicy", "DetCommonPolicy", "AtlasHLTPolicy", "ExternalPolicy", "TestPolicy", \
                    "TDAQPolicy", "AtlasFortranPolicy", "AtlasCommonPolicy", "AtlasCxxPolicy"]
    self.policy2 = ["AtlasDoxygen", "AGDD_DTD", "AGDD_XML", "AthenaDictionary"]

# some auxiliary lists: 
# package names starting lowercase (which are otherwise ignored), 
# and package names to skip
    self.notrans=["eflow", "egamma", "iPat", "muonEvent", "pyAMI", "taginfo","tau", "ulxmlrpcpp", "xKalman", "uuid", "xAOD"]
    self.pacskip=self.policy1 + ["JAGDD", "AtlasGraphicsFramework", "GraXML", "AMI", "pyAMI", "BkkJDBC", "ObjectBrowser", \
      "NOVA", "NovaTools", "AtlasSystemSettings", "AtlasRelease", \
      "RecExCommon", "Digitization", "iPatRecExample", "InDetRecExample", "MuidExample", "InDetDetDescrExample", \
      "AutoPrescaleEditor", "BunchGroupUpdate", "TriggerPanel", "Hephaestus"]
# containers to skip
    self.contskip=["External", "LCG_Interfaces"]
# use statements for externals to interpret (skip other)
    self.usenoskip=["AtlasROOT", "AtlasPOOL", "AtlasReflex", "AtlasCOOL", "AtlasCORAL", "AtlasSEAL", "AtlasPython", \
      "AtlasCppUnit", "GaudiInterface", "AtlasCLHEP", "AtlasBoost", "AtlasAIDA", "AtlasValgrind", "AtlasExpat", "AtlasXercesC", \
      "Ant", "AtlasExternalArea", "AtlasGSL", "AtlasHepMC", "AtlasSoQt", "G4Svc", "Geant4", "HepPDT", "MySQL", "mysql", \
      "RootConversions", "RootUtils", "Sherpa", "AtlasCoinInventor", "YODA"]
# use statements which define only linkage dependencies (skip them)
    self.uselinks=["TrigSteeringEvent", "TrigMuonEvent", "TrigBphysicsEvent", "TrigCaloEvent", "TrigCosmicEvent", \
      "TrigInDetEvent", "TrigParticle"]

# preset package versions cache (set later by do_cache to hold entire release)
    self.cachelist=[]
    self.nopatch=True


  def prepTroot(self):

# setup list of ROOT include files
    self.rootdone=True
    self.rootdir=path.expandvars("$ROOTSYS/include")
    self.rootincs=[]
    if path.isdir(self.rootdir):
      lns=listdir(self.rootdir)
      for l in lns:
        if self.patTroot.match(l) and not l in self.rootincs:
          self.rootincs+=[l]
    else:
      info(self, "Cannot check ROOT includes at %s. Exiting." %self.rootdir)
      ckrterm(self, 99)


  def prep(self):

# prepare access to cmt (by popen) and check if it works
    self.cmtool=path.expandvars("$CMTROOT") + "/" + path.expandvars("$CMTBIN") + "/cmt -q "
    out=popen(self.cmtool)
    res=out.readlines()
    pstat=out.close()
    if pstat: 
      info(self, self.cmtool + " was terminated with status %s. Exiting." %(pstat)) 
      ckrterm(self, 99)

# get project, release etc. from environmt (1st usable entry in CMTPATH)
# may be superseded per package

    do_cache(self)                  # generate cache in any case

    patchvar="$AtlasPatch"
    patchres=path.expandvars(patchvar) 
    self.nopatch= patchres == patchvar
    if not self.nopatch:
      detail(self, "This is a patch release: " + patchres)

class package:
  def __init__(self, c, pth):

# pth is the path to the present cmt directory

    patVers = compile("\-[0-9]{2}")

    self.ch=c

# extract package name from path
    cns=pth.split("/")
    l=cns[len(cns)-2]
    m=patVers.search(l)
    if m:
      self.thispac=m.string[:m.start()]  # potentially strip off -nn
    else:
      self.thispac=l
    self.above=cns[len(cns)-3]

# prepare project, release etc. for this package
    self.path=pth
    self.pacvers=do_cmt(c, "show version")
    self.severe=0

    projsl=do_cmt(c, "show projects")[0].split()

    self.projname=projsl[0]  ###new-emil
    self.release=projsl[1]
    self.relpath=projsl[3][:-1]
    detail(c, "Releasepath used: " + self.relpath)

    if self.projname == "DetCommon":
      self.policy="DetCommonPolicy"
    elif self.projname == "GAUDI":
      self.policy="GaudiPolicy"
    elif self.projname == "AtlasHLT":
      self.policy="AtlasHLTPolicy"
    else:
      self.policy="AtlasPolicy"

# optionally, prepare local copy of requirements (in dir from which checkreq was invoked)
    if c.o_local:
      reqbs="requirements_" + self.thispac + "_" + self.release
      self.reqpth=c.workpath + "/" + reqbs
      if not path.isfile(self.reqpth):
        if path.isdir(self.reqpth):
          info(c, "Requirements " + self.reqpth + " is a directory, not a file. Exiting.")
          ckrterm(c, 99)
        print "Copying requirements from", pth + "/requirements", "to", self.reqpth + "."
        copyfile(pth + "/requirements", self.reqpth)
        copyfile(pth + "/requirements", self.reqpth + "_orig")
        chmod(self.reqpth, 0644)
      print "Using", reqbs, "from working directory."
    else:
      self.reqpth=pth + "/requirements"
    detail(c, "Rqmts path used:  " + self.reqpth)

# clear results to be provided by do_check_n
# ...from the use stmts side (do_check_3):
    self.upacks=[]
    self.utrans=[]
    self.ulike=[]
    self.lpacks=[]
    self.ltrans=[]
# ...from the includes and linkopts side (do_check_4):
    self.ipacks=[]
    self.itrans=[]
    self.imap=[]
    self.ilike=[]
    self.rpacks=[]
    self.rmap=[]
# ...results from do_check_5
    self.umiss=[]
    self.supfl=[]

    self.chkmode=None

    self.req=[]
    self.macdefs=[]
    self.reqp=[]
    self.reqp_u=[]
    self.reqp_up=[]
    self.reqpub=[]
    self.cmttags=[]

  def prep(self, c, chkmode):

# chkmode = "all" or "priv":  use entire requirements file
#           "pub":            use only public requirements

    patDef=compile("\-D([a-zA-Z0-9_]*)")           # -D + macroname
                                                   # for the dict headers to be skipped
    patApat2=compile("apply_pattern lcgdict .* headerfiles[ ]*=\"[ ]*(\.\./" + self.thispac + "/[^\"]*)\"")

    self.chkmode=chkmode

# setup list of used compiler flags xxx from values (-Dxxx) in cmt macros
# use those found by cmt and those in our requirements

    self.macdefs=[]
    for mac in self.reqp:
      mm=mac.split()
      if mm[0] == "#macro_stuff":
        for im in mm[1:]:
          m=patDef.search(im)
          if m:
            self.macdefs+=[m.group(1)]
    #try from cmt 
    cppflags = do_cmt(c,"show macro_value use_pp_cppflags").split()
    #cppflags = popen("cmt show macro_value use_pp_cppflags").read().split()
    for cppflag in cppflags:
       m=patDef.search(cppflag)
       if m:
          self.macdefs+=[m.group(1)]
    self.macdefs=norm_list(self.macdefs)
    detail(c, "Defs for cpp: %s" % self.macdefs)

    for tag in do_cmt(c, "show tags"):
      self.cmttags+=[ tag.split()[0] ]

# prepare lists of requirements from file
    f=open(self.reqpth)
    aa=f.readlines()
    f.close()
    self.req=[]
    for l in aa:
      if l[len(l)-1] != "\n":
        self.req+=[l]
      else:
        self.req+=[l[:-1]]     # list of requirements
    self.reqp=[]               # list of requirements (pre-processed)
    self.reqp_u=[]             # list of use stmts only (pre-processed)
    self.reqp_up=[]
    self.reqpub=[]             # list of public/private status per requirement
    pubpri="public"
    previous="public"
    for l in prep_req(c, self.req):
      if l.startswith("private"):
        previous=pubpri
        pubpri="private"
      elif l.startswith("public"):
        previous=pubpri
        pubpri="public"
      elif l.startswith("end_public") or l.startswith("end_private"):
        pubpri=previous
      if chkmode=="all" or chkmode=="priv" or (chkmode=="pub" and pubpri=="public"):
        self.reqp+=[l]
        self.reqpub+=[pubpri=="public"]
        if l.startswith("use "):
          self.reqp_u+=[l]
          ls=l.split(" ")
          if len(ls) > 1:
            self.reqp_up+=[ls[1]]
        elif l.startswith("use_if "):
          tag = re.search('tag="?(\w+)"?', l).group(1)
          if tag in self.cmttags:
            pkg = re.search('pkg="?(\w+)"?', l).group(1)
            self.reqp_u += ["use " + pkg + " v*"]
        elif l.startswith("use_unless "):
          tag = re.search('tag="?(\w+)"?', l).group(1)
          if tag not in self.cmttags:
            pkg = re.search('pkg="?(\w+)"?', l).group(1)
            self.reqp_u += ["use " + pkg + " v*"]
        elif l.startswith("use_ifndef"):
          #extract the list of ppflags, compare to list of ppflags loaded. if none found then invent a use statement
          #structure is: use_ifndef pplist="my,list" pkg="My/Package"
          r = re.search('''pplist=['"](.+?)['"]''',l)
          if r:
            pplist = r.group(1).split(',')
            foundpp=False
            for pp in pplist:
              if pp in self.macdefs: foundpp=True
            if not foundpp:
              r2 = re.search('''pkg=['"](.+?)['"]''',l)
              if r2:
                pkg = r2.group(1).rsplit('/',1)
                pkg.reverse()
                newl = "use %s %s-* %s" % (pkg[0],pkg[0], pkg[1] if len(pkg)>1 else "")
                #print newl
                self.reqp_u+=[newl]
                ls=newl.split(" ")
                if len(ls) > 1:
                  self.reqp_up+=[newl[1]]
            
          
      else:
        m=patApat2.search(l)   # a bit ugly - note in requirements list which dict headers to skip
        if m:
          self.reqp+=["skipheaderfiles " + m.group(1)]

    self.ckrwarn=c.ckrvers + " warning for " + self.thispac + " (" + self.pacvers + "):"
    if c.o_detail:
      detail(c, "Current package: " + self.thispac + "(" + self.projname + "), version " + self.pacvers)
      detail(c, "---requirements file:----")
      for l in self.req:
        if l.strip() != "":
          print l
      detail(c, "---parsed:---------------")
      for l in self.reqp:
        print l
      detail(c, "-------------------------")



# check for modifications of important cppflags
    for ireq,mac in enumerate(self.reqp):
      pp=""
      mm=mac.split()
      if mm[0] in ["macro", "macro_append", "macro_remove"]:
        for ii,vv in enumerate(mm[1:]):
          if vv == "cppflags":
            pupub=self.reqpub[ireq]
            strts=True
            endss=False
            for ppp in mm[ii+2:]:
              if strts and ppp.startswith('"'):    # skip starting "
                ppp=ppp[1:]
                strts=False
              if ppp.endswith('"'):                # skip ending "
                ppp=ppp[:-1]
                endss=True
              ppp=ppp.strip()
              if pupub:                            # always bad if macro in public part
                pp+=ppp + " "
                ss="Compiler flags have been modified in PUBLIC part of requirements: "
                ssev=3
              else:
                ss="Compiler flags have been modified with: "
                ssev=2
                if mm[0] == "macro_remove":        # logic for removing from macro
                  if (ppp.startswith("-W") and not ppp.startswith("-Wno")) or ppp.startswith("-pedantic"):
                    pp+=ppp + " "
                elif mm[0] == "macro_append":      # logic for adding to macro
                  if ppp.startswith("-Wno") or ppp=="-g":
                    pp+=ppp + " "
                else:                              # always bad if macro is redefined altogether
                  pp+=ppp + " "
              if endss:
                break
            pp=pp.strip()
            if pp != "":
              self.ckrmsg(ssev, ss + mm[0] + " " + vv + " " + pp + ".", False)
            break


  def ckrmsg(self, sev, msg, cond=True):
# conditionally print message and update severity code
    if cond or self.chkmode != "pub" or self.ch.o_public != "both":
      if self.severe == 0:
        ckrprnt(self.ch, self.ckrwarn)
      if msg.endswith("\n"):
        msl=msg[:-1] + " (severity %1d)\n" %sev
      else:
        msl=msg + " (severity %1d)" %sev
      ckrprnt(self.ch, msl)
      if self.severe < sev:
        self.severe = sev


def info(c, str):
  ckrprnt(c, "--- " + str)


def detail(c, str):
# optional detailed output
  if c.o_detail:
    print "--d--", str


def norm_list(lst, skp=""):
# remove duplicates from and alphabetically sort lists
  lst1=[]
  for l in lst:
    if l not in lst1 and l != skp:
      lst1+=[l]
  lst1.sort()
  return lst1


def subtr_list(lst1, lst2):
# subtract lst2 from lst1 and alphabetically sort
# removes duplicates on the way
   lst=[]
   for l in lst1:
     if l not in lst2+lst:
       lst+=[l]
   lst.sort()
   return lst


def ckrexit(c, p):
# print exit message according to severity code, and exit
  if p.severe >= 3:
    ckrprnt(c, "\ncheckreq ERROR(s) in " + p.pacvers + " (max severity %1d)" %p.severe)
  elif p.severe != 0:
    ckrprnt(c, "\ncheckreq WARNING(s) in " + p.pacvers + " (max severity %1d)" %p.severe)
  else:
    ckrprnt(c, "\ncheckreq SUCCESS")
  if p.severe <= c.o_ignore:
    exit(0)
  exit(p.severe)


def ckrterm(c, excd):
# print fatal message and exit
  ckrprnt(c, "\ncheckreq FATAL")
  exit(excd)


def ckrprnt(c, msg):
# print msg, take care of newlines, possibly prepend (non-empty) lines
  for l in msg.split("\n"):
    if len(l) != 0:
      print c.o_nicos + l
    else:
      print


def lcgdictused(p):
# see if lcgdict used somewhere in requirements
  for l in p.reqp:
    if l.find("lcgdict") != -1:
      return True
  return False


def imppackage(p, pac):
# see if import stmt for package somewhere in requirements
  patImp=compile(".*import[ ]*=[ ]*" + pac)
  imp=False
  for l1 in p.reqp:
     if patImp.match(l1):
       imp=True
       break
  return imp


def cmtdirs(pth):
# return list of full paths of /cmt directories in the directory tree pth
# extra condition: file /cmt/requirements exists
# iterate over os.listdir - is faster than os.walk

  dirlst=[]
  more =[]
  for jj in listdir(pth):
    pp=pth+"/"+jj
    if path.isdir(pp):
      if jj == "cmt":
        if path.isfile(pp+"/requirements"):
          dirlst+=[pp]
      elif jj not in ["NICOS_area", "InstallArea", "CVS", "src", "doc"] and not jj.startswith("x86_") and not jj.startswith("i686-"):
        more+=[pp]

  while len(more) != 0:
    more1=[]
    for ii in more:
      kk=listdir(ii)
      if "cmt" in kk:
        pp=ii+"/cmt"
        if path.isfile(pp+"/requirements"):
          dirlst+=[pp]
      else:
        for jj in kk:
          pp=ii+"/"+jj
          if path.isdir(pp):
            if jj not in ["NICOS_area", "InstallArea", "CVS", "src", "doc"] and not jj.startswith("x86_") and not jj.startswith("i686-"):
              more1+=[pp]
    more=[]+more1

  return dirlst


def projct(c, pac):
# extract project of a package from cache
# returns empty string if package not found in cache
  refpr=""
  for l in c.cachelist:
    if l.find(":" + pac + "-") != -1:
      refpr=l.split(":")[0]
      break
  return refpr


def generuse(c, p, pac):

# generate use statement
# if possible from versions cache + any additions from original use statement
# else from existing use statement if any
# else use standard form but can't provide container

  patVer=compile(":([^:]*):" + pac + "-[0-9]{2}")
  foundit=False
  vers = pac + "-*"
  for l in c.cachelist:
    m=patVer.search(l)
    if m:
      cont = m.group(1)
      extra = "\t" + vers + "\t" + cont
      foundit=True
      break
  for us in p.reqp_u:
    uss=us.split(" ")
    if uss[1] == pac:
      if foundit:
        if len(uss) > 4:
          extra+="\t" + "\t".join(uss[4:])
      else:
        extra="\t" + "\t".join(uss[2:])
        foundit=True
      break
  if not foundit:
    extra="\t" + vers

  return ("use  " + pac + extra).expandtabs(32)



def deseal(lis, a, b):
# modify list of strings and sort alphabetically
# used for SEAL to Reflex translation (for now - will disappear)
  pp=[]
  for ii in lis:
    ij = ii.replace(a, b)
    if ij not in pp: 
      pp+=[ij]
  pp.sort()
  return pp


def filelst(c, n, incl, map):
# print list of files contributing to an included package
# using the include map
  inc="'" + incl + "'"
  ic=-n
  for im in map:
    if im.find(inc) != -1:
      if ic < 0:
        ckrprnt(c, "   " + im.split(" ")[0])
      ic+=1
  if ic > 0: 
    ckrprnt(c, "   and %d more" % ic)


def getline(pth,last=False):
# reads first or last line of a file
# returns line without \n
  ff=open(pth,"r") 
  if last:
# iterate through entire file
    for l in ff: ln=l
  else:
    ln=ff.readline()
  ff.close()
  return ln[:-1]


def fil2pac(c, st):

# translates header filenames of include files to package names

  patG4=compile("^G4[A-Za-z]*\.hh")

  transfil = {
  "qapplication.h":"Qt",
  "mysql.h":"MySQL",
  "CondDBTable.h":"CondDBMySQL",
  "Python.h":"AtlasPython",
  "python.hpp":"AtlasPython",
  "expat.h":"AtlasExpat",
  "FadsRunManager.hh":"FadsRun",
  "FadsSensitiveDetector.hh":"FadsSensitiveDetector",
  "dbORB.hh":"FadsDbORB",
  "XMLReader.hh":"FadsXMLParser",
  "DescriptionFactory.hh":"FadsXMLParser",
  "FadsMaterial.hh":"FadsMaterial",
  "MaterialManager.hh":"FadsMaterial",
  "FadsVolume.hh":"FadsGeometry",
  "GeometryManager.hh":"FadsGeometry",
  "ulx...h":"ulxmlrpcpp",
  "":""
  }

  str=st.strip()

# first catch ROOT include names
  if c.patTroot.match(str):
    if not c.rootdone:
      detail(c, "prepTroot triggered by %s in fil2pac" %str)
      c.prepTroot()
    if str in c.rootincs:
      return "AtlasROOT"
# then match via map
  try:
    return transfil[str]
  except:
# catch Geant4 cases
    if patG4.match(str):
      return "Geant4"
    else:
      return ""


def inc2pac(c, p, st):

# translates dirnames of include files to package names

  patQTVP1=compile("^Qt[0-9_a-zA-Z]+")

  transinc2 = {
# provide several mappings for backward compatibility with old releases
# then resolve against available use stmts
  "hltinterface":["HLTtdaqcommon","HLTtdaq"]
  }

  transinc = {
# ignore (in addition to most names starting with lowercase or _)
  "CXX":"",
  "HepODBMS":"",
  "IConditionsDB":"",
  "MySQL":"",
  "${package}":"",
  "$package":"",
  "StDbBroker":"",
  "Xm":"",
  "Inventor":"",
  "GL":"",
  "OpenGL":"",
  "ICE":"",
  "SM":"",
  "X11":"",
  "Xext":"",
  "MuCalDecode":"",
  "PDF":"",
  "TTCInfo":"",
# translations for TDAQ and TDAQCommon packages (20140305)
  "clocks":"HLTtdaqcommon",
  "compression":"HLTtdaqcommon",
##  "hltinterface":"HLTtdaqcommon", # now in transinc2 above
  "AccessManager":"HLTtdaq",
  "APE":"APEGlue",
  "asyncmsg":"HLTtdaq",
  "BeamSpotUtils":"HLTtdaq",
  "clips":"HLTtdaq",
  "cmdl":"HLTtdaq",
  "cmem_rcc":"HLTtdaq",
  "coca":"HLTtdaq",
  "coca_dal":"HLTtdaq",
  "config":"HLTtdaq",
  "CosNaming.idl":"HLTtdaq",
  "dal":"HLTtdaq",
  "DaqDbProxyUtils":"HLTtdaq",
  "DAQRelease":"HLTtdaq",
  "DataFlowMonitor":"HLTtdaq",
  "DataflowPolicy":"HLTtdaq",
  "dbe":"HLTtdaq",
  "dccommon":"HLTtdaq",
  "dcm":"HLTtdaq",
  "ddc":"HLTtdaq",
  "ddcInfo":"HLTtdaq",
  "DFConfiguration":"HLTtdaq",
  "DFdal":"HLTtdaq",
  "DFDebug":"HLTtdaq",
  "DFExceptions":"HLTtdaq",
  "dfinterface":"HLTtdaq",
  "DFRelease":"HLTtdaq",
  "DFSubSystemItem":"HLTtdaq",
  "DFTests":"HLTtdaq",
  "DFThreads":"HLTtdaq",
  "DFTools":"HLTtdaq",
  "DF_IS_Info":"HLTtdaq",
  "dqmf":"HLTtdaq",
  "dqm_archive":"HLTtdaq",
  "dqm_config":"HLTtdaq",
  "dqm_display":"HLTtdaq",
  "dvs":"HLTtdaq",
  "dvs_gui":"HLTtdaq",
  "dvs_tests":"HLTtdaq",
  "dynlibs":"HLTtdaq",
  "efio":"HLTtdaq",
  "elisa_client_api":"HLTtdaq",
  "emon":"HLTtdaq",
  "es":"HLTtdaq",
  "EventDuplication":"HLTtdaq",
  "EventStripping":"HLTtdaq",
  "ExpertSystemInterface":"HLTtdaq",
  "FarmMonitor":"HLTtdaq",
  "FarmTools":"HLTtdaq",
  "file_sampler":"HLTtdaq",
  "gatherer":"HLTtdaq",
  "genconfig":"HLTtdaq",
  "gnam":"HLTtdaq",
  "gnamdal":"HLTtdaq",
  "gnamDummyLib":"HLTtdaq",
##  "google":"HLTtdaq",
  "HLTMPPU":"HLTtdaq",
  "HLTPUDal":"HLTtdaq",
  "HLTRC":"HLTtdaq",
  "hltsv":"HLTtdaq",
  "IguiCommander":"HLTtdaq",
  "IguiPanels":"HLTtdaq",
  "io_rcc":"HLTtdaq",
  "is":"HLTtdaq",
  "ispy":"HLTtdaq",
  "Jers":"HLTtdaq",
  "ls":"HLTtdaq",
  "LTPidal":"HLTtdaq",
  "mda":"HLTtdaq",
  "mda_browser":"HLTtdaq",
  "mda_dal":"HLTtdaq",
  "MonInfoGatherer":"HLTtdaq",
  "monsvc":"HLTtdaq",
  "monsvcdal":"HLTtdaq",
  "mrs":"HLTtdaq",
  "msgdump":"HLTtdaq",
  "mts":"HLTtdaq",
  "mucaldal":"HLTtdaq",
  "MuCalStream":"HLTtdaq",
  "mucal_info":"HLTtdaq",
  "node2":"HLTtdaq",
  "oh":"HLTtdaq",
  "ohp":"HLTtdaq",
  "ohpplugins":"HLTtdaq",
  "oks":"HLTtdaq",
  "oks2coral":"HLTtdaq",
  "oksconfig":"HLTtdaq",
  "oks_utils":"HLTtdaq",
  "OMD":"HLTtdaq",
  "omni":"HLTtdaq",
  "omniParTcl.h":"HLTtdaq",
  "omniPy":"HLTtdaq",
  "omnithread":"HLTtdaq",
  "omnithread.h":"HLTtdaq",
  "OnlinePolicy":"HLTtdaq",
  "OnlineRelease":"HLTtdaq",
  "opmon":"HLTtdaq",
  "owl":"HLTtdaq",
  "PartitionMaker":"HLTtdaq",
  "pbeast":"HLTtdaq",
  "pmg":"HLTtdaq",
  "PmgGui":"HLTtdaq",
  "pmgpriv":"HLTtdaq",
  "pmgpub":"HLTtdaq",
  "ProcessManager":"HLTtdaq",
  "protobuf":"HLTtdaq",
  "pudummy":"HLTtdaq",
  "pudummydal":"HLTtdaq",
  "pvss2cool":"HLTtdaq",
  "Pythia8Plugins":"Pythia8",
  "QTUtils":"HLTtdaq",
  "queues":"HLTtdaq",
  "racksdal":"HLTtdaq",
  "rc":"HLTtdaq",
  "rcc_corbo":"HLTtdaq",
  "rcc_error":"HLTtdaq",
  "rcc_rodbusy":"HLTtdaq",
  "rcc_time_stamp":"HLTtdaq",
  "RCDBitString":"HLTtdaq",
  "RCDExampleModules":"HLTtdaq",
  "RCDExampleTriggers":"HLTtdaq",
  "RCDJtagChain":"HLTtdaq",
  "RCDLtp":"HLTtdaq",
  "RCDLTPdal":"HLTtdaq",
  "RCDLtpi":"HLTtdaq",
  "RCDLtpiModule":"HLTtdaq",
  "RCDLTPModule":"HLTtdaq",
  "RCDMenu":"HLTtdaq",
  "RCDModuleDesign":"HLTtdaq",
  "RCDTtc":"HLTtdaq",
  "RCDUtilities":"HLTtdaq",
  "RCDVme":"HLTtdaq",
  "RCInfo":"HLTtdaq",
  "RCUtils":"HLTtdaq",
  "rdb":"HLTtdaq",
  "rdbconfig":"HLTtdaq",
  "ResourcesInfo":"HLTtdaq",
  "rm":"HLTtdaq",
  "Rm-Gui":"HLTtdaq",
  "rn":"HLTtdaq",
  "RobinTestSuite":"HLTtdaq",
  "robin_kermit":"HLTtdaq",
  "robin_ppc":"HLTtdaq",
  "RODBusy":"HLTtdaq",
  "RODBusydal":"HLTtdaq",
  "RODBusyModule":"HLTtdaq",
  "roib":"HLTtdaq",
  "ROSApplication":"HLTtdaq",
  "ROSasyncmsg":"HLTtdaq",
  "ROSBufferManagement":"HLTtdaq",
  "ROSCore":"HLTtdaq",
  "ROSDescriptor":"HLTtdaq",
  "ROSEventFragment":"HLTtdaq",
  "ROSEventInputManager":"HLTtdaq",
  "ROSfilar":"HLTtdaq",
  "ROSGetInput":"HLTtdaq",
  "ROSInfo":"HLTtdaq",
  "ROSInterruptScheduler":"HLTtdaq",
  "ROSIO":"HLTtdaq",
  "ROSMemoryPool":"HLTtdaq",
  "ROSMemoryPoolNP":"HLTtdaq",
  "ROSModules":"HLTtdaq",
  "ROSModulesNP":"HLTtdaq",
  "ROSMonitor":"HLTtdaq",
  "ROSObjectAllocation":"HLTtdaq",
  "ROSRCDdrivers":"HLTtdaq",
  "ROSRobin":"HLTtdaq",
  "ROSRobinNP":"HLTtdaq",
  "ROSslink":"HLTtdaq",
  "ROSsolar":"HLTtdaq",
  "ROSTester":"HLTtdaq",
  "ROSUtilities":"HLTtdaq",
  "RunControl":"HLTtdaq",
  "runner":"HLTtdaq",
  "SFOng":"HLTtdaq",
  "SFOTZ":"HLTtdaq",
  "siom":"HLTtdaq",
  "siomdal":"HLTtdaq",
  "siom_info":"HLTtdaq",
  "system":"HLTtdaq",
##  "tbb":"HLTtdaq",
  "TDAQExternal":"HLTtdaq",
  "TDAQExtJars":"HLTtdaq",
  "TDAQPolicy":"HLTtdaq",
  "TestManager":"HLTtdaq",
  "threadpool":"HLTtdaq",
  "threads":"HLTtdaq",
  "tmgr":"HLTtdaq",
  "training":"HLTtdaq",
  "transport":"HLTtdaq",
  "trgCommander":"HLTtdaq",
  "TriggerCommander":"HLTtdaq",
  "TriggerDB":"HLTtdaq",
  "TRP":"HLTtdaq",
  "ttcpr":"HLTtdaq",
  "TTCvidal":"HLTtdaq",
  "TTCviModule":"HLTtdaq",
  "vme_rcc":"HLTtdaq",
  "wmi":"HLTtdaq",
  "xmext":"HLTtdaq",
# keep older mappings to HLTtdaq no longer present in new mapping
  "ac":"HLTtdaq",
  "cocaIPC":"HLTtdaq",
  "commander":"HLTtdaq",
  "dcmessages":"HLTtdaq",
  "DCM":"HLTtdaq",
  "efd":"HLTtdaq",
  "errorRecovery":"HLTtdaq",
  "ErrorReporting":"HLTtdaq",
  "histmon":"HLTtdaq",
  "HLTPU":"HLTtdaq",
  "instrumentation":"HLTtdaq",
  "l2sv":"HLTtdaq",
  "msg":"HLTtdaq",
  "msgconf":"HLTtdaq",
  "msginput":"HLTtdaq",
  "msgsctp":"HLTtdaq",
  "msgtcp":"HLTtdaq",
  "msgudp":"HLTtdaq",
  "msgunix":"HLTtdaq",
  "NSGLIB":"HLTtdaq",
  "OnlineRecovery":"HLTtdaq",
  "pt":"HLTtdaq",
  "ptdummy":"HLTtdaq",
  "PTIO":"HLTtdaq",
  "PUIO":"HLTtdaq",
  "rcdal":"HLTtdaq",
  "RunController":"HLTtdaq",
  "SFIOEmulators":"HLTtdaq",
  "sysmon":"HLTtdaq",
  "sysmonapps":"HLTtdaq",
  "triggerCommander":"HLTtdaq",
# special translations for VP1
  "qwt":"AtlasExternalArea",
  "Inventor/...":"AtlasCoinInventor",
  "Inventor/Qt/...":"AtlasSoQt",
  "Q...":"VP1Qt",   # from #include <Qyyy>  -  without / or .
# special Muons
  "AmdbAgeH":"AmdbAgeH AmdbAge",
  "AmdbAthH":"AmdbAthH AmdbAth",
  "AmdbCoreH":"AmdbCoreH AmdbCore",
  "AmdbStandH":"AmdbStandH AmdbStand",
  "BFieldAgeH":"BFieldAgeH BFieldAge",
  "BFieldAthH":"BFieldAthH BFieldAth",
  "BFieldCoreH":"BFieldCoreH BFieldCore",
  "BFieldStandH":"BFieldStandH BFieldStand",
  "MuonboxAthH":"MuonboxAthH MuonboxAth",
  "MuonboxAtrH":"MuonboxAtrH MuonboxAtr",
  "MuonboxCoreH":"MuonboxCoreH MuonboxCore",
  "MuonboyAthH":"MuonboyAthH MuonboyAth",
  "MuonboyAtrH":"MuonboyAtrH MuonboyAtr",
  "MuonboyCoreH":"MuonboyCoreH MuonboyCore",
  "MuUtiAgeH":"MuUtiAgeH MuUtiAge",
  "MuUtiCoreH":"MuUtiCoreH MuUtiCore",
  "MuUtiStandH":"MuUtiStandH MuUtiStand",
# external (generators) translations
  "SHERPA-MC":"Sherpa",
  "SHERPA":"Sherpa",
  "ATOOLS":"Sherpa",
  "EvtGenBase":"EvtGen",
  "EvtGenModels":"EvtGen",
  "EvtGenExternal":"EvtGen",
  "Mt2":"AtlasmT2",
  "Photos":"Photospp",
  "Tauola":"Tauolapp",
  "LHAPDF":"Lhapdf",
# translate others
  "Eigen":"AtlasEigen",
  "LWH":"Rivet",
  "HepMC":"AtlasHepMC",
  "boost":"AtlasBoost",
  "AIDA":"AtlasAIDA",
  "CLHEP":"AtlasCLHEP",
  "cppunit":"AtlasCppUnit",
  "Expat":"AtlasExpat",
  "dom":"AtlasXercesC",
  "framework":"AtlasXercesC",
  "parsers":"AtlasXercesC",
  "sax":"AtlasXercesC",
  "util":"AtlasXercesC",
  "xercesc":"AtlasXercesC",
  "atXercesC":"atutil",
  "ICondDBTest":"ConditionsDBTest",
  "eformat":"DataCollection",
  "EventStorage":"DataCollection",
  "l2hlt":"DataCollection",
  "ExN01":"G4Ex",
  "ExN02":"G4Ex",
  "ExN03":"G4Ex",
  "ExN04":"G4Ex",
  "Physics":"G4Svc",
  "GaudiKernel":"GaudiInterface",
  "Gaudi":"GaudiInterface",
  "geant321":"geant3",
  "g4std":"Geant4",
  "LArG4Hbook":"LArG4",
  "hectb":"LArHECTBCnv",
  "emtblib":"LArTBCnv",
  "valgrind":"AtlasValgrind",
  "gsl":"AtlasGSL",
  "HepPID":"HepPDT",
  "dqm_core":"DQM_Core",
  "CXX/...":"PerfMonEvent",
  "frontier_client":"Frontier_Client",
# Gaudi services SHOULD NOT be used directly but through interface
  "THistSvc":"GaudiInterface",
# ...except for these
  "ApplicationMgr":"GaudiSvc",
  "JobOptionsSvc":"GaudiSvc",
# POOL packages used to be in LCG, now in ATLAS - translations remain unchanged:
  "Collection":"AtlasPOOL",
  "CollectionBase":"AtlasPOOL",
  "CollectionUtilities":"AtlasPOOL",
  "DataSvc":"AtlasPOOL",
  "FileCatalog":"AtlasPOOL",
  "LFCCatalog":"AtlasPOOL",
  "ObjectRelationalAccess":"AtlasPOOL",
  "PersistencySvc":"AtlasPOOL",
  "POOLCore":"AtlasPOOL",
  "RelationalStorageService":"AtlasPOOL",
  #"RootCollection":"AtlasPOOL",
  "RootStorageSvc":"AtlasPOOL",
  "StorageSvc":"AtlasPOOL",
  "XMLCatalog":"AtlasPOOL",
# generated get_trans output comes here
## older kept
  "cint":"AtlasROOT",
  "Graf":"AtlasROOT",
  "PluginManager":"AtlasSEAL",
  "SealKernel":"AtlasSEAL",
## new automatic 20130924
  "Cintex":"AtlasROOT",
  "Fit":"AtlasROOT",
  "Math":"AtlasROOT",
  "Minuit2":"AtlasROOT",
  "RooStats":"AtlasROOT",
  "TMVA":"AtlasROOT",
  "Reflex":"AtlasReflex",
  "CoolApplication":"AtlasCOOL",
  "CoolKernel":"AtlasCOOL",
  "CoralBase":"AtlasCORAL",
  "CoralKernel":"AtlasCORAL",
  "RelationalAccess":"AtlasCORAL"
  }

  str=st.strip()

# first catch some explicit lowercase names
  for nt in c.notrans:
    if str.startswith(nt):
      return str
# then match via map
  try:
    strt = transinc[str]
    if p.above == "APR" and strt == "AtlasPOOL":
      return str
    else:
      return strt
  except:
# try non-unique map and resolve against use stmts
    try:
      strtl = transinc2[str]
      if strtl[0] in p.reqp_up:
        return strtl[0]
      elif strtl[1] in p.reqp_up:
        return strtl[1]
      else:
        return strtl[0]+"_or_"+strtl[1]         
    except:
# catch more special VP1 cases
      if patQTVP1.match(str):  #include <Qtxxx/...>
        return "VP1Qt"
# ignore remaining lowercase+_ names
      elif c.patLund.match(str[:1]):
        return ""
      else:
# nothing matches at all, return original value
        return str


def lib2pac(c, st):

# translates linkopts arguments to package names

  patGeant = compile("^LHEP[_A-Z]*|^QGSP[_A-Z]*")

  translib = {
# ignore (in addition to most names starting with lowercase or _)
  "Xm":"",
  "Inventor":"",
  "dl":"",
  "GL":"",
  "OpenGL":"",
  "ICE":"",
  "m":"",
  "SM":"",
  "X11":"",
  "Xext":"",
  "MuCalDecode":"",
# special translations for VP1 ###
  "qwt":"AtlasExternalArea",
# standardize names
  "PyROOT":"AtlasPyROOT",
# generated get_trans output
  "cint":"AtlasROOT",
  "Cintex":"AtlasROOT",
  "Graf":"AtlasROOT",
  "Fit":"AtlasROOT",
  "Math":"AtlasROOT",
  "Minuit2":"AtlasROOT",
  "RooStats":"AtlasROOT",
  "TMVA":"AtlasROOT",
# translate others
  "Mt2":"AtlasmT2",
  "AthenaPoolExampleLcgDictionaryX":"AthenaPoolExampleLcgDictionary",
  "DataHeaderDict":"SGTools",
  "DetDescrDict":"DetDescrDictionary",
  "G3b":"geant3",
  "G3extrap":"geant3",
  "G3fluka":"geant3",
  "G3gheisha":"geant3",
  "G3graphics":"geant3",
  "G3inter":"geant3",
  "G3micap":"geant3",
  "G3p":"geant3",
  "Examples":"Geant4",
  "Packaging":"Geant4",
  "HepMC_IO":"HepMC",
  "lcg_FML":"AtlasSEAL",
# generated get_trans output for Dicts comes here
## older kept
  "APIndependentDict":"InsituRepresentation",
  "APRootInterfaceEntryDict":"InsituRepresentation",
  "tauEventEnumsDict":"tauEvent",
## new automatic 20130924
  "ARA_MuonEventTPCnvDict":"MuonEventTPCnv",
  "AthenaDBTestRecDataDict":"AthenaDBTestRec",
  "AthExThinningEventDict":"AthExThinning",
  "BPhysObjectsDict":"BPhysAnalysisObjects",
  "CollectionDict":"CollectionBase",
  "dqm_toolsDict":"dqm_algorithms",
  "egammaEnumsDict":"egammaEvent",
  "egammaEnumsDict":"egammaInterfaces",
  "FeatureClassDict":"TrigEventARA",
  "HelloSerializerWorldDict":"TrigSerializeResult",
  "InDetBCM_EventAthenaPoolCnvDict":"InDetBCM_EventAthenaPool",
  "InDetConditionsAthenaPoolCnvDict":"InDetConditionsAthenaPool",
  "InDetEventAthenaPoolCnvDict":"InDetEventAthenaPool",
  "InDetLowBetaDict":"InDetLowBetaInfo",
  "iPatTrackContainerDict":"iPatRecEvent",
  "IProxyDict":"AthenaKernel",
  "LArBadChannelDBToolsDict":"LArBadChannelTool",
  "McEventDict":"GeneratorObjects",
  "MCTruthClassifierEnumsDict":"MCTruthClassifier",
  "MuonCoinDataDict":"MuonTrigCoinData",
  "MuonPrepDataDict":"MuonPrepRawData",
  "MuonRDOCnvDict":"MuonEventAthenaPool",
  "OLD_MuonEventTPCnvDict":"MuonEventTPCnv",
  "PhotonD3PD_AddReflexDict":"PhotonD3PDMaker",
  "RootUtilsPyROOTDict":"RootUtils",
  "SimulationHitDict":"ForwardRegion_SimEv",
  "SimulationHitTPCnvDict":"ForwardRegion_EventTPCnv",
  "StacoEventDict":"STACOEvent",
  "SummaryDict":"TrkTrackSummary",
  "T2L1ToolsDict":"TrigT2CaloJet",
  "tauEnumsDict":"tauEvent",
  "TrigDecisionDict":"TrigDecisionEvent",
  "TrigTauToolsDict":"TrigTauD3PDMaker",
  "V0VertexDict":"TrkV0Vertex",
  "ZeeCalibDict":"egammaPhysCalib"
  }

  str=st.strip()

# first catch ROOT include names
  tstr="T" + str + ".h"
  if c.patTroot.match(tstr):
    if not c.rootdone:
      detail(c, "prepTroot triggered by %s in lib2pac" %tstr)
      c.prepTroot()
    if tstr in c.rootincs:
      return "AtlasROOT"
# catch some explicit lowercase names
  for nt in c.notrans:
    if str.startswith(nt):
      return str
# then match via map
  try:
    return translib[str]
  except:
# catch more Geant4 cases
    if patGeant.match(str):
      return "Geant4"
# strip off any trailing Dict from xxxDict
    elif str.endswith("Dict"):
      return str[:str.rfind("Dict")]
# ignore remaining lowercase+_ names
    elif c.patLund.match(str[:1]):
      return ""
    else:
      return str


def do_cmt(c, cmd):

# invokes "cmt -q cmd" as subprocess
# takes a shortcut for cmd "show version"
# 
# returns stdout of cmt

  if cmd == "show version" and path.isfile("version.cmt"):
    return getline("version.cmt")

  out=popen(c.cmtool + cmd)
  res=out.readlines()
  pstat=out.close()
  if pstat:
    return ""
  else:
    if len(res) < 1:
      return ""
    elif len(res) < 2:
      return res[0][:-1].strip()
    else:
      ret=[]
      for r in res:
        ret+=[r[:-1].strip()]
      return ret


def do_cpp(p, file):

# resembles some cpp functionality
# to find out #include references while
# taking into account #ifdef etc. and
# comments, all only to the required
# extent
#
#   key     begin   end   logic      parameter
#           block   block
#   #ifdef   yes          regard     check if defined
#   #ifndef  yes          discard    check if defined
#   #else    yes    yes   invert
#   #endif          yes
#   #include              if regard  store
#   #if      yes          ignore     ignore
# 
# returns a list of included files

  patInc=compile("^[ \t]*#[ \t]*include[ \t]*[\"<]([^\">]+)[\">]")   # cpp include stmt; group is the included object
  patIfd=compile("^[ \t]*#[ \t]*ifdef[ \t]+([a-zA-Z0-9_]+)")         # cpp ifdef stmt; group is macro name
  patIf1=compile("^[ \t]*#[ \t]*if[ \t]+defined[ \t]*\(([a-zA-Z0-9_]+)\)")    # alternatively: if defined(...)
  patIfnd=compile("^[ \t]*#[ \t]*ifndef[ \t]+([a-zA-Z0-9_]+)")       # cpp ifndef stmt; group is macro name
  patIfn1=compile("^[ \t]*#[ \t]*if[ \t]+!defined[ \t]*\(([a-zA-Z0-9_]+)\)")  # alternatively: if !defined(...)
  patEls=compile("^[ \t]*#[ \t]*else")                               # cpp else stmt
  patEnd=compile("^[ \t]*#[ \t]*endif")                              # cpp endif stmt
  patIf=compile("^[ \t]*#[ \t]*if[ \t\(]+")                          # cpp if stmt (needed to account for levels)

  ff=open(file, "r")
  inpt=ff.readlines()
  ff.close()

  val=True # see if #include to be regarded or not
  vals=[]  # stack of val
  ret=[]
  cmntd=False

  for li in inpt:
    if li.endswith("\n"):
      lin=li[:-1]
    else:
      lin=li

    stc=lin.find("/*")                     # treat these comments
    enc=lin.find("*/")
    if lin.strip().startswith("//"):       # // ... /* ... can't start a comment but
      stc=-1                               # // ... */ ... can end a comment
    cmntd1=cmntd
    if stc != -1 and enc != -1:
      if stc < enc:                        # /*...*/
        lin=lin[:stc] + lin[enc+2:]
        cmntd1=False
        cmntd=False
      else:                                # ...*/   /*...
        lin=lin[enc+2:stc]
        cmntd1=True
        cmntd=False
    elif stc != -1:                        # /*...
      lin=lin[:stc]
      cmntd1=True
      cmntd=False
    elif enc != -1:                        # ...*/
      lin=lin[enc+2:]
      cmntd1=False
      cmntd=False

    if not cmntd:
      m=patIfd.search(lin)                 ##ifdef
      if m == None:
        m=patIf1.search(lin)               ##if defined()
      if m:
        vals.append(val)                   # push present value
        if m.group(1) not in p.macdefs:
          val=False                        # switch to disregard if not defined
      else:
        m=patIfnd.search(lin)              ##ifndef
        if m == None:
          m=patIfn1.search(lin)            ##if !defined()
        if m:
          vals.append(val)                 # push present value
          if m.group(1) in p.macdefs:
            val=False                      # switch to disregard if defined
        elif patIf.match(lin):             ##if
          vals.append(val)                 # just so it can be popped again
        elif patEls.match(lin):            ##else
          val = not val                    # switch to opposite
        elif patEnd.match(lin):            ##endif
          if len(vals) > 0:
            val=vals.pop()                 # pop value from outer level
          else:
            p.ckrmsg(2, "#ifdef blocks bad in " + file + " ?")
        elif val:
          m=patInc.search(lin)             ##include
          if m:
            ret+=[m.group(1)]              # extract and remember include path/file
    cmntd=cmntd1
  return ret


def do_cache(c):

# provide faster access to explicit package name versions for version
# checking and for writing use statements.
# generate it from the use stmts in <project>Release/cmt/requirements
# within CMTPATHs

  detail(c, "do_cache called")
  cpths=path.expandvars("$CMTPATH").split(":")
  pacentered=[]
  for cpth in cpths:
    for ll in listdir(cpth):
      for pp in c.projmap.keys():
        if ll == pp + "Release":
          pll=cpth + "/" + ll + "/cmt/requirements"
          f=open(pll)
          aa=f.readlines()
          f.close()
          for a in aa:
            if a.startswith("use "):
              ac=a.split()
              if len(ac) >= 3:
                if len(ac) >=4:
                  accont=ac[3]
                else:
                  accont=""
                lac=pp + ":" + accont + ":" + ac[2]
                if ac[1] not in pacentered:
                  pacentered+=[ac[1]]
                  c.cachelist+=[lac]
  c.cachelist.sort()
  detail(c, "packages found: %d" %(len(c.cachelist)))


def prep_req(c, rqmts):

# pre-parse requirements:
# - join continuation lines
# - take care of \r, \t, multiple white space
# - resolve macros  ${xxx} or $(xxx) in requirements files by invoking cmt show macro_value xxx

  keep = ["use","library","application","import","package","lcgdict","AtlasSEAL","AtlasReflex", \
          "linkopts","apply_pattern","cppdebugflags","private","public", "macro"]

  patMac = compile("\$[{(]([a-zA-Z0-9_]*)[})]")

  rqmts1=[]
  lstMac = []
  lstRes = []
  for l in rqmts:
    m=patMac.search(l)
    if m:
      ms=m.group(0)
      mss=m.group(1)
      if mss in lstMac:
        exp=lstRes[lstMac.index(mss)]
      else:
        exp=do_cmt(c, "show macro_value " + mss)
        lstMac+=[mss]
        lstRes+=[exp]
      rqmts1+=[l.replace(ms, exp)]
##      print ">>>", ms, mss, exp
    else:
      rqmts1+=[l]

  rqmtso=[]
  lnc=""
  for lin in rqmts1:
    if lin.strip().endswith("\\"):   # join continuation lines
      lnc+=lin.replace("\\", " ")
      continue
# remove comments and useless whitespace
    l=" ".join((lnc+lin).split("#")[0].split())
    lnc=""
    if l != "":
      kp=False
      for w in keep:  # keep only lines relevant to checkreq
        if l.find(w) != -1:
          kp=True
          break
      if kp:
        lst=l.strip()
        rqmtso+=[lst]
# resolve cmt macros (also resolving tags) in case it contains a -Dxxx
        if lst.startswith("macro") and lst.find("-D") != -1:
          ls=lst.split()
          exp=do_cmt(c, "show macro_value " + ls[1])
          rqmtso+=["#macro_stuff " + ls[1] + " " + exp]

  return rqmtso


def chk_files(c, p, ftocheck):

  vp1Pat=compile("^Q[0-9_a-zA-Z]+$")
  jivPat=compile("^ulx[mr][_a-z]*\.h")

# analyse #includes of files listed as to-be-checked
# list idents of included files in incparsed
  incparsed=[]
  incdirs=[]
  incfils=[]
# these leave as results
  incpacs=[]    # the main result: list of included packages
  incmap=[]     # map of files to included packages
  translist=[]  # map of included dirs/files to included packages

  if len(ftocheck) != 0:

# check if dictionary file is identified but not existing 
    if p.chkmode != "pub":
      no_dictfile=True
      for ftc in ftocheck:
        if ftc.endswith(p.thispac + "Dict_gen.h"):
          detail(c, "Generated dictionary is referenced: " + ftc)
          no_dictfile=False
          if not path.isfile(ftc):
            p.ckrmsg(2, "No Dict_gen.h found (yet) for package: " + p.thispac)
            p.ckrmsg(2, "Consider re-running checkreq after it is generated, else could cause warnings for unnecessary use stmts.")
          break
      if no_dictfile==True:
        detail(c, "No generated dictionary referenced for package: " + p.thispac)

    for ftc in ftocheck:
      incpl=[]
      if path.isfile(ftc):
        for mm in do_cpp(p, ftc):
          ixm=mm.find("./")
          if ixm == -1:                             # ignore relative paths
            incparsed+=[mm]
            ix=mm.find("/")
            if ix != -1:
              dn=mm[:ix]
              if dn not in ["main_prog", "Objy", "tmpqt_extra", ".."]:
                incpl+=[dn]
              ifip=inc2pac(c, p, dn)
            else:
              ifip=fil2pac(c, mm)
              if ifip != "":
                incpl+=[mm]
# treat includes from <package>Dict_gen as if there was a use stmt for them
# caution - side effect on p.ulike !!
            if ( ftc.endswith(p.thispac + "Dict_gen.h") or ftc.endswith("_gen.cpp") ) and ifip != "":
              p.ulike+=[ifip]
              detail(c, "Imply use stmt for include from Dict_gen: " + ifip)
      else:
        p.ckrmsg(2, "File to check does not exist and is skipped: " + ftc) 
      if len(incpl) != 0:
        incmap+=["%s includes: %s" % (ftc, norm_list(incpl))]
    incparsed=norm_list(incparsed)

# analyse idents further - first for the standard case,
# extract the directory from the ident (normally name of referenced package)
    for idt in incparsed:
      if not idt.startswith("src/") and not idt.startswith("dict/"):
        ix=idt.find("/")
        if ix != -1:
          dn=idt[:ix]
          if dn not in ["main_prog", "Objy", "tmpqt_extra", ".."]:
            incdirs+=[dn]
# translate the dirname to package name
            tip=inc2pac(c, p, dn)
            if tip != "":
              incpacs+=[tip]
          ifip=idt[ix+1:]
        else:
          ifip=idt
# posibly translate filename to package name
        ifip=fil2pac(c, idt[ix+1:])
        if ifip != "":
          incfils+=[idt[ix+1:]]
          incpacs+=[ifip]
##        else:
### posibly translate filename to package name
##          ifip=fil2pac(c, idt)
##          if ifip != "":
##            incfils+=[idt]
##            incpacs+=[ifip]

# special cases
    for idt in incparsed:
# ...VP1 (partly only if NOT in GeoModel packages)
      if p.above != "GeoModel" and idt.startswith("Inventor/"):
        dn="Inventor/..."
        incdirs+=[dn]
        incpacs+=[inc2pac(c, p, dn)]
        if idt.startswith("Inventor/Qt/"):
          dn="Inventor/Qt/..."
          incdirs+=[dn]
          incpacs+=[inc2pac(c, p, dn)]
      elif vp1Pat.match(idt):   #include <Qyyy>  -  without / or .
        dn="Q..."
        incdirs+=[dn]
        incpacs+=[inc2pac(c, p, dn)]
# ...PerfMonEvent
      elif idt.startswith("CXX/"):
        dn="CXX/..."
        incdirs+=[dn]
        incpacs+=[inc2pac(c, p, dn)]
# ...JiveXML
      elif jivPat.match(idt):
        fn="ulx...h"
        incfils+=[fn]
        incpacs+=[fil2pac(c, fn)]

    incdirs=norm_list(incdirs)

# setup list of includes-to-packages
    for inc in incdirs:
# identify illegal direct usage of Gaudi services
      if inc == "THistSvc":
        p.ckrmsg(2, "%s should be used via the interface, GaudiKernel/I%s." % (inc, inc))
      inct=inc2pac(c, p, inc)
      if inct == "": inct="-"
      translist+=[inct + ":(from:include:" + inc + ")"]

# setup list of files-to-packages
    for inc in incfils:
      inct=fil2pac(c, inc)
      translist+=[inct + ":(from:include:" + inc + ")"]
# through with files to check

  return incpacs, incmap, translist
  

def do_check_1(c, p):

# first part of checking: preliminary checks, no requirements file
# needed for that
# 
# return None if nothing else to check, 1 else

  if not path.isfile("requirements"):
    print "Did not find a requirements file. Checks skipped."
    return None

  if not path.basename(p.path) == "cmt":
    print "Requirements file not in cmt but:", p.path, ". Checks skipped."
    return None

  ncmt=0
  for iip, iid, iif in walk(".."):
    if iip.endswith("/cmt"): ncmt+=1
  if ncmt != 1:
    print "Container package. Checks skipped."
    return None

  if p.thispac.endswith("Release"):
    pastr=p.thispac[:-len("Release")]
    pacve=compile(p.thispac+"\-"+pastr+"\-[0-9]{2}\-[0-9]{2}")
    if pastr == p.projname or pacve.match(p.pacvers):
      print "Container package. Checks skipped."
      return None

  if p.above in c.contskip:
    print p.above, "package. Checks skipped."
    return None

  if p.thispac in c.pacskip:
    print "Special package. Checks skipped."
    return None

  if p.thispac.endswith("RunTime"):
    print "Runtime package. Checks skipped."
    return None

  return 1


def do_check_2(c, p):

# check version and container of used packages
#
# sets severity 3 if error, returns nothing

# extract the versions from the use statements. Allowed are:
#   use foo
#   use foo *
#   use foo v*
#   use foo foo*
#   use foo foo-*                   (the normal case)
# the following should not be used anymore:
#   use foo foo-nn*
#   use foo foo-nn-*
#   use foo foo-nn-nn*
#   use foo foo-nn-nn-*
### the following are deprecated altogether:
###   use foo foo-nn
###   use foo foo-nn-nn-nn
  for l in p.reqp_u:
    uu=l.split(" ")

    if len(uu) <=2:                      # skip if there is no version field at all
      p.ckrmsg(2, "Version field missing in " + l + ".")

    else:
      gotit = uu[2] in ["*", "v*", ""]   # always allow these wildcards - no further checks if these are used
      if not gotit:
        patVers = compile(uu[1]+"\*|" + uu[1]+"\-\*")
        gotit = patVers.match(uu[2])
        if not gotit:
          patVers = compile(uu[1]+"\-[0-9]{2}\*|" + uu[1]+"\-[0-9]{2}\-\*")
          gotit = patVers.match(uu[2])
          if not gotit:
            patVers = compile(uu[1]+"\-[0-9]{2}\-[0-9]{2}\*|" + uu[1]+"\-[0-9]{2}\-[0-9]{2}\-\*")
            gotit = patVers.match(uu[2])

##          if not gotit:
##            patVers = compile(uu[1]+"\-[0-9]{2}")
##            gotit = patVers.match(uu[2])
##          if not gotit:
##            patVers = compile(uu[1]+"\-[0-9]{2}\-[0-9]{2}\-[0-9]{2}")
##            gotit = patVers.match(uu[2])

          if gotit:
            p.ckrmsg(1, "Version " + uu[2] + " used in package " + p.thispac + ": should not give version numbers anymore.")

        if gotit:
          if c.o_needcache and c.nopatch:             # these checks only if cache available
            ii=uu[2].find("*")
            if ii != -1:
              u=uu[2][:ii]
            else:
              u=uu[2]
            fnd=False
            for ll in c.cachelist:
              ls=ll.split(":")
              if ls[2].startswith(u):
                fnd=True
                cntnr=ls[1]
                vers=ls[2]
                break
            if fnd:
              detail(c, "Actual version for " + u + "*: " + vers)
              if len(uu) > 3 and uu[3] != cntnr and uu[3] != cntnr + "/" and not uu[3].startswith("-"):
                p.ckrmsg(2, "Container of " + u + "*  should be " + cntnr + " instead of " + uu[3] + ".")
            else:
              p.ckrmsg(2, "Version " + u + "* used in package " + p.thispac + " not found in release.")

      if not gotit:
        p.ckrmsg(3, "Version " + uu[2] + " used in package " + p.thispac + " has bad name or format.")


def do_check_3(c, p):

# do checking on basis of requirements alone
#
# sets severity if error

  lopPat1=compile(p.thispac + "_linkopts[^\"]*\"([^\"]*)\"")
  lopPat2=compile(p.thispac + "_dict_linkopts[^\"]*\"([^\"]*)\"")
  lopPat=compile("-l[ ]*([a-zA-Z0-9_]*)")
  dictPat=compile("(.*)Dict$")
  allowpac=["AthenaKernel", "HeapMon", "PerfMonComps", "StoreGateBindings", "SGTools", "RootStorageSvc", \
            "RDBAccessSvc", "AthenaRootComps", "IOVDbSvc", "RegistrationServices", "VirtualFlags"]

  reqpackages=[]
  packages=[]
  deflibraries=[]
  utranslst=[]
  treatlikeuse=[]
  libnams=[]
  libpacs=[]
  libtrans=[]

  for l in p.reqp:
    if l.startswith("library "):
      uu=l.split(" ")
      if uu[1] != p.thispac:
        deflibraries+=[uu[1]]

  for l in p.reqp_u:
    uu=l.split(" ")
    if l.find("no_auto_imports") == -1:
      reqpackages+=[uu[1]]
    elif imppackage(p, uu[1]) or (p.thispac == "POOLCore" and uu[1] == "TestTools") or \
                                 (lcgdictused(p) and uu[1] in ["AtlasSEAL", "AtlasReflex"]):
      reqpackages+=[uu[1]]
      detail(c, "Require " + uu[1] + " despite -no_auto_imports")

# get packages found in linkopts (in requirements)
  for ind,l in enumerate(p.reqp):
    if l.startswith("macro"):
      if not l.startswith("macro_remove"):
        m=lopPat1.search(l)
        if not m: m=lopPat2.search(l)
        if m:
          for mm in lopPat.findall(m.group(1)):
            mmt=lib2pac(c, mm)
            libnams+=[mm]
            libpacs+=[mmt]
# check for possible abuse of linkopts
      if p.chkmode != "pub" and p.thispac not in allowpac:
        m=l.split()[1]
        if m.endswith("_linkopts") and not m.startswith(p.thispac):
          # Allow it for other libraries we build in this package.
          linkopt_ok = False
          for dl in deflibraries:
            if m.startswith(dl): linkopt_ok = True
          if not linkopt_ok:
            if p.reqpub[ind]:
              p.ckrmsg(1, p.thispac + " changes linkopts for " + m[:-len("_linkopts")] + " in public:")
            else:
              p.ckrmsg(1, p.thispac + " changes linkopts for " + m[:-len("_linkopts")] + ":")
            ckrprnt(c, "  " + l)


  if len(libpacs) != 0:
    detail(c, "Linkopts-statements for the following packages were found:")
    for ip in libpacs:
      detail(c, "  " + ip)

# store translations for these
  for i in range(len(libnams)):
    mm=libpacs[i]
    if mm == "":
      mm="-"
    libtrans+=[mm + ":(from:linkopts:" + libnams[i] + ")"]
  libtrans=norm_list(libtrans)
  libnams=norm_list(libnams)
  libpacs=norm_list(libpacs)

# see if use <pac> -no_auto_imports present for a <pac>Dict package
# if so add it to packages (as if import <pac> were present)
  for ln in libnams:
    m=dictPat.search(ln)
    if m:
      mm=m.group(1)
      reqpackages+=[mm]
      detail(c, "use " + mm + "(Dict) despite -no_auto_imports")

  if len(deflibraries) != 0:
    detail(c, "The following libraries are defined by this package:")
    detail(c, deflibraries)

# in treatlikeuse, set up list of things which are implicitely "use"d
# ...first the defined libraries:
  treatlikeuse+=deflibraries
# ...packages found in TDAQ_COMMON:
  treatlikeuse+=["circ", "circ_proc", "MuCalDecode"]
# ...and these
  treatlikeuse+=["X11", "Xm", "Inventor"]
### ...and this, to account for thing only available online:
##  treatlikeuse+=["HLTtdaq"]

  if len(reqpackages) != 0:
    detail(c, "The following packages are claimed to be used by this package:")
    detail(c, reqpackages)

  baduse1 = ["COOL", "POOL", "Reflex", "XercesC", "Boost", "GSL", "CORAL", "HepMC"]
  baduse2 = ["SEAL", "AtlasSEAL"]

# check if use stmt for policy (unless checking only private requirements)
  polcyfound = p.policy in reqpackages
  if not polcyfound and p.projname == "AtlasHLT":   # be more permissive for AtlasHLT packages
    for rp in ["AtlasPolicy", "TDAQPolicy"]:
      if rp in reqpackages:
        p.policy=rp
        polcyfound=True
        break
  if not polcyfound:
    p.ckrmsg(1, "Please add a use-statement for " + p.policy + ".", False)

  policiesx=subtr_list(c.policy1+c.policy2, [p.policy])   #...#

  for rp in reqpackages:
### check for CBNT use
##    if rp.startswith("CBNT"):
##      p.ckrmsg(1, "CBNT packages will be phased out (use %s is present)." %rp, False)
# check if use stmt for own package
    if rp == p.thispac:
      p.ckrmsg(1, "Please remove use statement for its own package.", False)
# warn if package name XXX = COOL, POOL, Reflex, etc. instead AtlasXXX
    if rp in baduse1:
      rrp = "Atlas" + rp
      utranslst+=[rrp + ":(from:use:" + rp + ")"]
      p.ckrmsg(1, "Please replace 'use " + rp + "' by 'use " + rrp + "'.", False)
# translate if package name SEAL, AtlasSEAL instead of AtlasReflex
    elif rp in baduse2:
      rrp = "AtlasReflex"
      utranslst+=[rrp + ":(from:use:" + rp + ")"]
      p.ckrmsg(1, "Please replace 'use " + rp + "' by 'use " + rrp + "'.", False)
    else:
      rrp = rp
# ignore Policies and xxxRunTime
    if rrp not in policiesx and not rrp.endswith("RunTime"):
      rrrp=rrp
      if rrp in baduse1:
        rrrp = "Atlas" + rrp
      elif rrp in baduse2:
        rrrp = "AtlasReflex"
      packages+=[rrrp]

  dualuse=False
  libthis=False
  dbgmac=False
  for l in p.reqp:
# check if both apply_pattern dual_use_library .cxx  and  library <package> .cxx present in requirements
# this would result in double compilation and duplicate library contents
    appchk=l.split()
    if appchk[0]=="apply_pattern" and \
       appchk[1] in ["dual_use_library", "named_dual_use_library", "component_library", "installed_library"]:
##    if l.startswith("apply_pattern dual_use_library") and l.find("*.cxx") != -1: 
      dualuse=True
      libappl=appchk[1]
      linappl=l
    elif appchk[0]=="library" and appchk[1]==p.thispac:
##    elif l.startswith("library " + p.thispac) and l.find("*.cxx") != -1:
      libthis=True
      liblist=appchk[2:]
# check if statements for debugging left by mistake in requirements
    elif l.startswith("macro cppdebugflags") or l.startswith("macro_remove componentshr_linkopts"):
      dbgmac=True
  if dualuse and libthis:
    coli=[]
    for coco in liblist:
      if linappl.find(coco) != -1:
        coli+=[coco]
    if len(coli) != 0:
      p.ckrmsg(3, "Both " + libappl + " and library " + p.thispac + " compile %s. Please check." %coli, False)
  if dbgmac:
    p.ckrmsg(2, "Debugging options (cppdebugflags, remove componentshr_linkopts) present. Please check.", False)

# check package statements:
  npst=0
  for l in p.reqp:
    if l.startswith("package "):
      if npst == 0: 
        pst=l
      npst+=1
  if npst == 1:
    pna=pst.split(" ")[1]
    ii=pna.rfind("/")
    if ii != -1:
      pna1=pna[ii+1:]
    else:
      pna1=pna
    if pna1 != p.thispac:
      p.ckrmsg(2, "Misspelt package statement in " + p.thispac + ": " + pst + ".", False)
    elif pna != p.thispac:
      p.ckrmsg(2, "Incorrectly formed package statement in " + p.thispac + ": " + pst + ".", False)
  else:
    p.ckrmsg(2, "Missing or multiple package statements in " + p.thispac + ".", False)

# return results
  return packages, utranslst, treatlikeuse, libpacs, libtrans


def do_check_4(c, p):

# here comes the treatment of include files. 
# look for #includes in these files:
#   constituents files stated in requirements
#   recursively add included files
# also treat python imports and includes
# also deal with linkopts from requirements file.

  pincPat1=compile("^[ \t]*include[ \t]*\([ \t]*[\"\']([^/]*)/.*[\"\'][ \t]*\)")
  pincPat2=compile("^[ \t]*from[ \t]+([^.]*)\..*import")
  pincPat3=compile("^[ \t]*import[ \t]+([^.]*)\.")
  mapVP1={"qt4based_library":["VP1Qt"], "vp1plugin":["VP1Base", "VP1Qt"]}
  mapApat={"poolcnv":["AthenaPoolUtilities", "+dyn+"], \
           "pooliohandler":["AthenaPoolUtilities", "+dyn+"], \
           "sercnv":["TrigSerializeUtils"], \
           "UnitTest_run":["TestTools"], \
           "ant_jar":["Ant"], \
           "do_genconf":["GaudiPython"]}
  mapApat1={"poolcnv":["AthenaPoolCnvSvc", "GaudiInterface"], \
            "pooliohandler":["AthenaPoolCnvSvc", "AtlasPOOL", "AtlasSEAL", "DataModel", "GaudiInterface"], \
            "sercnv":["TrigSerializeCnvSvc", "GaudiInterface"], \
            "CppUnit":["AtlasCppUnit", "TestPolicy"], \
            "APRTest_run":["TestTools", "AtlasCppUnit", "FileCatalog", "PersistencySvc", "StorageSvc"], \
            "APR_test":["TestTools", "AtlasCppUnit", "TestPolicy"]}
  mapApat2={"poolcnv":["AtlasSealCLHEP"]}
  patApat=compile("[\" ]-s=[^ ]*/([^ ]*) ")
  patApat1=compile("skipheaderfiles (.*)")

  packages=[]
  translist=[]
  treatlikepac=[]
  rpackages=[]

# get the list of source/header files from constituents
# also bring in the .icc files
  constit=[]
  condirs=[]
  for con in do_cmt(c, "show constituents"):
    if con.startswith("library ") or con.startswith("application "):
      cons=con.split()
      for el in cons:
        if el.find(".") != -1 and not el.startswith("-") :
          concon=el.replace(path.abspath(".."),"..")
          constit+=[concon]
          condir=path.basename(path.dirname(concon))
          if condir != "" and not condir in condirs:
            condirs+=[condir]

# some special treatment for VP1
# caution - side effect on p.ulike !!
  for l in p.reqp:
    for pvp in mapVP1.keys():
      if l.startswith("apply_pattern " + pvp):
        detail(c, "Use VP1Qt from pattern " + pvp + " added")
        p.ulike+=mapVP1[pvp]
        detail(c, "Constituent files *.cxx for pattern " + pvp + " added")
        constit+=["*.cxx"]
  constit=norm_list(constit)

  detail(c, "Constituents: %s:" % len(constit))
  detail(c, constit)

  skipdicth=[]
# make list of lcgdict header files to be ignored
  for l in p.reqp:
    m=patApat1.search(l)
    if m:
      skipdicth+=m.group(1).split()
  detail(c, "Skip dict headers: %s" % skipdicth)

# get all files with relevant extensions
  present=[]
  present_vis=[]
  present_py=[]
  extsvis=[".hxx", ".hpp", ".h", ".hh", ".icc"]
  exts=extsvis+[".cxx", ".cpp", ".c", ".cc", ".F", ".age", ".inc"]
# skip the following directories unless used by constituents
  skipdirs=subtr_list(["doc", "cmt", "share", "test", "root"], condirs)
  detail(c, "Skipdirs: %s" % skipdirs)
  for iip, iid, iif in walk(".."):
    iipp=iip.split("/")
    for ii in iif:
      iipii=iip + "/" + ii
      if iipii not in skipdicth:
        # MN: skip the xxx/dict/ directory as well.  disabled for now
        # if len(iipp) > 1 and iipp[1] not in skipdirs and ( len(iipp) <= 2 or iipp[2] != "dict"): 
        if len(iipp) > 1 and iipp[1] not in skipdirs : 
          for sfx in exts:
            if ii.endswith(sfx):
              present+=[iipii]
          for sfx in extsvis:
            if ii.endswith(sfx):
              present_vis+=[iipii]
          for iji in c.o_pydirs:    ###:::###
            if iipii.startswith("../" + iji + "/") and ii.endswith(".py"):
              present_py+=[iipii]
              break
  present=norm_list(present)
  present_vis=norm_list(present_vis)
  present_py=norm_list(present_py)

  npresent=len(present)
  detail(c, "Files present: %s:" % npresent)
  detail(c, present)

# files visible to other packages (.h*, .icc of subdir ../<thispac>)
  fvisible=[]
  for fv in present_vis:
    if fv.startswith("../" + p.thispac):
      fvisible+=[fv]
  fvisible=norm_list(fvisible)

  detail(c, "Files visible: %s:" % len(fvisible))
  detail(c, fvisible)

# always consider the visibles
  ftocheck=[] + fvisible

# skip if checking only public files
  if p.chkmode != "pub":

# setup list of files to check for #includes
# start with the files used for constituents
    moreto=[] + constit
    moreto1=[] + constit
    while len(moreto) != 0:
      moreto=[]
      for ii in moreto1:
# store in list a new file if contained in package
# this stores the full path as it uses the 
        ii1 = ii.replace("*", "[a-zA-Z0-9_]+").replace(".", "\.") + "$"
        if ii[:1].isalnum():
          ii2 = ".*[^a-zA-Z0-9_]+" + ii1 + "|^" + ii1
        else:
          ii2 = ".*" + ii1
        iiPat=compile(ii2)
        fnd=False
        for jj in ftocheck:
          if iiPat.match(jj):
            fnd=True
            break
        if not fnd:
          for jj in present:
            if iiPat.match(jj):
              moreto+=[jj]
      moreto=norm_list(moreto)
      if len(moreto) == 0:
        break
      ftocheck+=moreto
# analyse #includes of newly listed files
# remember included files for next round
      moreto1=[]
      for fil in moreto:
        for mm in do_cpp(p, fil):
          ixm=mm.find("./")
          if ixm != -1:
            mm=mm[ixm+2:]
          moreto1+=[mm]
      moreto1=norm_list(moreto1)
    ftocheck=norm_list(ftocheck)

  detail(c, "Files to check: %s of %s:" % (len(ftocheck),npresent))
  detail(c, ftocheck)

  detail(c, "Python files to check: %s:" % len(present_py))
  detail(c, present_py)

# now analyse files listed as to-be-checked
  incpacs, incmap, translist = chk_files(c, p, ftocheck)
  incmap=norm_list(incmap)

# check if lcgdict used
  if lcgdictused(p):
    incpacs+=["AtlasSEAL"]
    translist+=["AtlasSEAL:(from:lcgdict)"]

# require a policy use stmt
# must be public normally - at least if publicly visible files present  #...#
  if len(fvisible) != 0 and p.chkmode == "pub":   # or p.chkmode != "pub":
    incpacs+=[p.policy]
    translist+=[p.policy + ":(from:policy)"]

# check python files
  incmpy=[]
  for ipy in present_py:
    ff=open(ipy, "r")
    lin=ff.readlines()
    ff.close()
    for l in lin:
      m=pincPat1.search(l[:-1])
      if not m:
        m=pincPat2.search(l[:-1])
      if not m:
        m=pincPat3.search(l[:-1])
      if m:
        mm=m.group(1).strip()
        if mm != p.thispac:
          incmpy+=["%s includes: %s" % (ipy, [mm])]
          inct=inc2pac(c, p, mm)   ###:::###
          if inct != "":
            rpackages+=[inct]
          else:
            inct="-"
          translist+=[inct + ":(from:py_include:" + mm + ")"]
  incmpy=norm_list(incmpy)
  rpackages=norm_list(rpackages)

# something for .age files
  for ip in present:
    if ip.endswith(".age"):
      incpacs+=["agetof"]
      translist+=["agetof:(from:files:*.age)"]
      break

# check explicitely for some runtime dependencies #???
  if p.thispac == "AthenaPoolMultiTest":
    incpacs+=["AthenaPoolExampleAlgorithms"]
    translist+=["AthenaPoolExampleAlgorithms:(from:jobOptions:dependency)"]
  if p.thispac in ["CppUnitExample", "CppUnitSGServiceExample", "AnalysisTest", "CLIDSvc", \
                   "RootConversions", "EventLoopTest", "ByteStreamCnvSvc", "TrigDecisionEvent", \
                   "AthenaMPTest", "Tests"]:
    treatlikepac+=["TestTools"]
##  if p.thispac == "AnalysisTest" or p.thispac == "CppUnitSGServiceExample":
##    incpacs+=["TestTools"]
##    translist+=["TestTools:(from:jobOptions:dependency)"]

# take care of external generators etc. which don't have recognizable include directory
# i.e. absorb use statements for them if present
  uextskp=[]
  ulnkskp=[]
  for us in p.reqp_u:
    uu=us.split(" ")
    if len(uu) > 3:
      if uu[3].lower() == "external":
        if not uu[1] in c.usenoskip:
          uextskp+=[uu[1]]
      elif uu[1] in c.uselinks:
        ulnkskp+=[uu[1]]
  if len(uextskp) != 0:
    detail(c, "Absorb use statements for externals: %s" % norm_list(uextskp))
  if len(ulnkskp) != 0:
    detail(c, "Absorb use statements for linking: %s" % norm_list(ulnkskp))
  treatlikepac+=uextskp+ulnkskp

# absorb use stmts for these if present
  treatlikepac+=["X11", "Xm", "Inventor"]
  treatlikepac+=["PyJobTransforms", "PyJobTransformsCore", "PyJobTransformsMisc"]
  treatlikepac+=["PATJobTransforms", "RecJobTransforms", "SimuJobTransforms"]
  treatlikepac+=["AtlasROOT"]

# handle some special apply_patterns
  for rq in p.reqp:
    for apat in mapApat.keys():
      if rq.startswith("apply_pattern " + apat):
        val=mapApat[apat]
        for v in val:
          if v != "+dyn+":
            incpacs+=[v]
            translist+=[v + ":(from:apply_pattern:" + apat + ")"]
          elif p.chkmode != "pub":               # ignore "-s=" references if apply_pattern is in public section
            mgr=patApat.findall(rq)
            for mm in mgr:
              if c.patLund.match(mm[:1]):        # skip directories starting with lowercase or _...
                yesdo=False
                for nt in c.notrans:             # ...except these
                  if mm.startswith(nt):
                    yesdo=True
                    break
              else:
                yesdo=True
              if yesdo:
                incpacs+=[mm]
                translist+=[mm + ":(from:apply_pattern:" + apat + ")"]
    for apat in mapApat1.keys():
      if rq.startswith("apply_pattern " + apat) or (p.thispac == "AthenaPoolUtilities" and apat == "pooliohandler"):
        val=mapApat1[apat]
# caution - side effect on p.ulike !!
        p.ulike+=val
        detail(c, "Use %s from pattern %s were added" % (val, apat))
    for apat in mapApat2.keys():
      if rq.startswith("apply_pattern " + apat):
        val=mapApat2[apat]
        treatlikepac+=val
    

  incpacs=norm_list(incpacs)
    

# require AthenaPoolUtilities plus packages stated in apply_pattern poolcnv statements
# inherit use statement
# also consider these use statements in the package where the patterns are defined
# potentially require AtlasSealCLHEP if poolcnv


# now add results from #include and linkopts analysis
  packages=norm_list(incpacs+p.lpacks, p.thispac)      
  translist=norm_list(translist+p.ltrans)

# provide the list of includedirectories this package defines
# consider visible .h files
# if filename is xxxDict.h, take xxxDict
# skip the normal cases (xxxDict is <package>Dict)
  if c.o_detail:
    defns=[]
    for l in fvisible:
      if l.endswith("Dict.h"):
        ls=l.split("/")
        lk=ls[len(ls)-1]
        pk=lk[:len(lk)-len(".h")]
        if pk != p.thispac + "Dict":
          defns+=[pk]
    if len(defns) != 0:
      detail(c, "%s defines: %s" % (p.thispac, norm_list(defns)))

    if len(incpacs) != 0:
      detail(c, "Include-statements for the following packages were found:")
      for ip in incpacs:
        detail(c, "  " + ip)

    if len(incmap) != 0:
      detail(c, "---include map:----------")
      for im in incmap:
        detail(c, "  " + im)
      detail(c, "-------------------------")
    if len(incmpy) != 0:
      detail(c, "---py include map:-------")
      for im in incmpy:
        detail(c, "  " + im)
      detail(c, "-------------------------")

# return the results
  return packages, translist, treatlikepac, incmap, rpackages, incmpy


def do_check_5(c, p, p1=None):

# finally check dependencies by comparing use/linkopts/include results
# p is the project object with the uselists, p1 the one with the includelists
# they are identical in the traditional checkreq usecase

# result: list of unnecessary uses, list of missing uses - no printout

  if p1 == None:
    p1 = p

# for now, do some SEAL to Reflex replacement as in old checkreq
  p1.ipacks=norm_list(deseal(p1.ipacks, "AtlasSEAL", "AtlasReflex"), p1.thispac)
  p.upacks =norm_list(deseal(p.upacks, "AtlasSEAL", "AtlasReflex"), p.thispac)
  p1.ilike =norm_list(deseal(p1.ilike, "AtlasSEAL", "AtlasReflex"), p1.thispac)
  p.ulike  =norm_list(deseal(p.ulike, "AtlasSEAL", "AtlasReflex"), p.thispac)
  p1.itrans=deseal(p1.itrans, "AtlasSEAL:(", "AtlasReflex:(")
  p.utrans =deseal(p.utrans, "AtlasSEAL:(", "AtlasReflex:(")

# now check if there are packages from use stmts which are not in those from includes/linkopts
  superfluses=[]
  if c.o_python:   ###:::###
# resolve uses against python includes only for option -y
    p1p=p1.ipacks+p1.ilike+p1.rpacks
  else:
    p1p=p1.ipacks+p1.ilike
  for used in p.upacks: 
    if used not in p1p:
      superfluses+=[used]

# now check if there are packages from includes/linkopts which are not in those from use stmts
  missuses=[]
  if c.o_python:   ###:::###
# resolve python includes against uses only for option -y
    p1p=p1.ipacks+p1.rpacks
  else:
    p1p=p1.ipacks
  for reqd in p1p:
    if reqd not in p.upacks+p.ulike:
      missuses+=[reqd]

  return norm_list(missuses), norm_list(superfluses)


def do_check_6(c, p):

# produce output for inter-project checks etc.

  for tt in p.itrans:
    detail(c, "trans2pac: " + tt.replace(":", " "))
  for tt in p.utrans:
    detail(c, "trans2use: " + tt.replace(":", " "))


# check inter-project dependencies - works only if cache available
  if not c.nopatch:
    detail(c, "This is a patch release - project depency check skipped.")
  if c.o_needcache and c.nopatch and p.projname in c.projmap.keys():
    badlist=c.projmap[p.projname]
    if len(badlist) != 0:
      detail(c, "Check project dependencies")
      for inc in p.rpacks:
        refpr=projct(c, inc)
        if refpr in badlist:
          p.ckrmsg(1, "Project runtime dependency: " + p.thispac + "(" + p.projname + ") -> " + inc + "(" + refpr + ") in files:")
          filelst(c, 5, inc, p.rmap)
      for inc in p.ipacks:
        refpr=projct(c, inc)
        if refpr in badlist:
          p.ckrmsg(2, "Static project dependency: " + p.thispac + "(" + p.projname + ") -> " + inc + "(" + refpr + ") in files:")
          filelst(c, 5, inc, p.imap)
      for inc in p.upacks:
        refpr=projct(c, inc)
        if refpr in badlist:
          p.ckrmsg(2, "Project dependency: " + p.thispac + "(" + p.projname + ") -> " + inc + "(" + refpr + ")" + \
            " in use statements.")

  if c.o_detail:
    detail(c, "Depending on these packages:")
    for ip in norm_list(p.ipacks + [p.policy]):
      print "# " + p.thispac + "(" + p.projname + ") => " + ip + "(" + projct(c, ip) + ")"


def do_check_7(c, p, superfluses1, p1=None):

# produce output from comparison results (unnecessary use stmts)
# p is the package analysed as "all" or "priv"
# p1 if given is the same package analysed as "pub"

  if p1 == None:
    p1 = p

  superfluses2=subtr_list(superfluses1, [p.policy])   #...#

  # Ignore fortran-only packages.
  superfluses=subtr_list(superfluses2, ['Lhef_i', 'McAtNlo_i'])

# output for use stmts which are not in those from includes/linkopts
  if len(superfluses) != 0:
    key="--"
    if p1.chkmode == "pub":
      if c.o_public == "both":
        p.ckrmsg(2, "\nThe following packages should have private instead of public use statements.\n")
        key="-+"
      else:
        p.ckrmsg(2, "\nThe following packages need no (public) use statements.\n")
    else:
      p.ckrmsg(2, "\nThe following packages are apparently not needed.\n")
    for used in superfluses:
      txt=used
      for tr in p.utrans:
        if tr.startswith(used + ":"):
          txt=tr.replace(":", " ")
          break
      ckrprnt(c, key + " " + txt)


def do_check_8(c, p, missuses, superfluses, p1=None, subtract=False):

# produce output from comparison results (missing use stmts)
# p is the package analysed as "all" or "priv"
# p1 if given is the same package analysed as "pub"; then p is "priv"

  if p1 == None:
    needpri=False
    p1 = p
    nltrans=p.itrans
  else:
    needpri=True
    nltrans=norm_list(p.itrans+p1.itrans)

# output for includes/linkopts which are not in those from use stmts
  if len(missuses) != 0:
    keyp="++ "
    if p1.chkmode == "pub":
      if subtract:
        p.ckrmsg(3, "\nThe following packages (referenced as indicated) need public instead of private use statements.\n")
        keyp="+- "
      else:
        p.ckrmsg(3, "\nThe following packages (referenced as indicated) need public use statements.\n")
    elif needpri:
      p.ckrmsg(3, "\nThe following packages (referenced as indicated) need private use statements.\n")
    else:
      p.ckrmsg(3, "\nThe following packages (referenced as indicated) have no use statements.\n")
    for reqd in missuses:
      for tr in nltrans:
        if tr.startswith(reqd + ":"):
          txt=keyp + tr.replace(":", " ")
# if there are also unnecessary use statements, check for close similarity
# i.e. one string contained in the other either way, ignoring case
          for used in superfluses:
            if used.lower().find(reqd.lower()) != -1 or reqd.lower().find(used.lower()) != -1:
              txt+="    <<<==== hint: similar to " + used
              break
          if txt.find("from include") != -1:
            ckrprnt(c, txt + " in files:")
            orig=txt.split()[4][:-1]
            filelst(c, 5, orig, p.imap)
          elif txt.find("from py_include") != -1:  ###:::###
            ckrprnt(c, txt + " in py files:")
            orig=txt.split()[4][:-1]
            filelst(c, 5, orig, p.rmap)
          else:
            ckrprnt(c, txt)



def do_write(c, p, uall, upall=None):

# write out use statements
# p is the package analysed as "all" or "priv"
# uall are required uses (public ones if pmiss given)
# pmiss are required private uses if given
# p1 if given is the same package analysed as "pub"; then p is "priv"

  all = subtr_list(uall, [p.policy])
  all.insert(0, p.policy)
  if upall == None:
    pall = []
  else:
    pall = [] + upall

  if len(all) == 0 and len(pall) == 0:
    detail(c, "No use-statements to be resolved.")
  else:
    detail(c, all)
    if upall != None:
      detail(c, "Public use-statements for the following packages:")
      print "public"
    else:
      detail(c, "Use-statements for the following packages:")
    for pac in all:
      lin = generuse(c, p, pac)
      print lin

# same again for the extra (private) use stmts
    if len(pall) != 0:
      detail(c, "Private use-statements for the following packages:")
      detail(c, pall)
      print "private"
      for pac in pall:
        lin = generuse(c, p, pac)
        print lin
      print "end_private"


def do_modif(c, p, supflu, miss, pmiss=None, p1=None):

# modify use statements in requirements file
# p is the package analysed as "all" or "priv"
# supflu are uses to be removed/replaced
# miss are missing uses (public ones if pmiss given)
# pmiss are missing private uses if given

  all=[] + miss
  if p1 != None:
    pp=p1                 # check if policy-use present in public if given
  else:
    pp=p
  fnd=False
  for us in pp.reqp_u:
    if us.startswith("use " + p.policy):
      fnd=True
      break
  if not fnd:
    all.insert(0, p.policy)
    supfl=[p.policy]      # if not present possibly comment policy-use from private uses
  else:
    supfl=[]
  if pmiss == None:
    pall=[]
  else:
    pall=[] + pmiss

# add original use names to list of use stmts to be commented
  for us in supflu:
    supfl+=[us]
    for tr in p.utrans:
      trs=tr.split(":")
      if us == trs[0]:
        supfl+=[trs[3][:-1]]

  patUse = compile("^[ \t]*use[ \t]")
  part1=[]
  part2=[]
  part3=[]
  preuse=True        # find insertion point for new use stmts (after 1st existing use if policy found, else before)
  cmntd=False
  anychange=False
  for l in p.req:
    sup=False
    for pac in supfl:
      patSup=compile("^[ \t]*use[ \t]+" + pac + "[ \t]")
      if patSup.match(l):
        sup=True
        break
    if sup:
      cmntd =True
      anychange=True
      ll="#--#" + l  # comment out any unnecessary use stmts
    else:
      ll=l 
    if preuse and not fnd and patUse.match(l):
      preuse=False
    if preuse:
      part1+=[ll]
    else:
      part3+=[ll]
    if preuse and patUse.match(l):
      preuse=False
  if cmntd:
    print "Commented unnecessary use statements in " + p.reqpth + "."

  firstapp=True
  if len(all) == 0 and len(pall) == 0:
    print "No use-statements to be added."
  else:
    part2+=["\n#++#checkreq has inserted the following use statements:"]
    if len(all) != 0:
      if pmiss != None:
        part2+=["public"]
      for pac in all:
        lin = generuse(c, p, pac)

# append extra public uses
        if firstapp:
          print "Inserting use statements into " + p.reqpth + "."
          firstapp=False
        part2+=[lin]
        anychange=True
      if pmiss != None:
        part2+=["end_public"]

# same again for the extra (private) use stmts
    if len(pall) != 0:
      part2+=["private"]
      for pac in pall:
        lin = generuse(c, p, pac)

# append extra private use stmts
        if firstapp:
          print "Inserting private use statements into " + p.reqpth + "."
          firstapp=False
        part2+=[lin]
        anychange=True
      part2+=["end_private"]
    if cmntd:
      part2+=["#--#use are those use statements commented out by checkreq.\n"]
    else:
      part2+=["#--#\n"]
    
# output
  ff=open(p.reqpth, "w")
  for l in part1+part2+part3:
    ff.write(l + "\n")
  ff.close()

  if anychange:
    print "Requirements", p.reqpth, "have been modified by checkreq."

# try to copy result back to original place
    try:
      copyfile(p.reqpth, p.path + "/requirements")
      print "Modified requirements copied back to", p.path + "/requirements."
    except:
      print "Could not copy modified requirements back to", p.path + "/requirements."
  else:
    print "No modifications necessary in requirements", p.reqpth + "."



def do_checks(c, p):

# do all checks. PWD is the /cmt of the package to be checked.

#!#  needpub=["GaudiInterface"]  # list of packages which need to be public if included #!#
  ignpub=["GaudiInterface", "YODA"]   # list of packages to ignore in public/private distiction #!#
 
  goon=do_check_1(c, p)       # basic checks (once only, even if mode "both")

  if goon:
    if c.o_public != "both":
# analyse package as "all" or "pub"
      p.prep(c, c.o_public)   
      do_check_2(c, p)

      p.upacks, p.utrans, p.ulike, p.lpacks, p.ltrans = do_check_3(c, p)
      p.ipacks, p.itrans, p.ilike, p.imap, p.rpacks, p.rmap = do_check_4(c, p)
      p.umiss, p.supfl = do_check_5(c, p)
      do_check_6(c, p)                    # inter-project checks
      do_check_7(c, p, p.supfl)           # unnecessary use stmts
      do_check_8(c, p, p.umiss, p.supfl)  # missing use stmts

      if c.o_writeuse:
        if c.o_local:
          do_modif(c, p, p.supfl, p.umiss)
        else:
          do_write(c, p, p.ipacks)

    else:
# analyse the same package twice - first as as "priv", then as "pub"
      p.prep(c, "priv")       # it is already instantiated once so need only prep
      do_check_2(c, p)        # do next-to-basic checks only once

      p1=package(c, p.path)   # extra instance of same package
      p1.prep(c, "pub")

      for pi in [p, p1]:
        pi.upacks, pi.utrans, pi.ulike, pi.lpacks, pi.ltrans = do_check_3(c, pi)
        pi.ipacks, pi.itrans, pi.ilike, pi.imap, pi.rpacks, pi.rmap = do_check_4(c, pi)

#!#      for inpu in needpub:    #!#
#!#        if inpu in p.ipacks:  #!#
#!#          p1.ipacks+=[inpu]   #!#
#!#          detail(c, "Forced to public scope: " + inpu)  #!#

# check "priv" instance - compare uses with includes
      p.umiss, p.supfl = do_check_5(c, p)
      do_check_6(c, p)                                    # inter-project checks only once
      do_check_7(c, p, p.supfl)                           # list unnecessary use stmts

# check "pub" instance - compare uses with includes
      p1.umiss, p1.supfl = do_check_5(c, p1)

# now do crosschecks between private and public
#     p.supfl                                             # those don't need use
      uprinpub=subtr_list(p1.supfl, p.supfl)              # for those private use suffices but have public use
      uprinpub=subtr_list(uprinpub,ignpub)  #!#
      pubneed=subtr_list(p1.umiss, p.upacks)              # those need public (and have no private use)
      pubnpri=subtr_list(p1.umiss, pubneed)               # those need public use but have private use
      pubnpri=subtr_list(pubnpri,ignpub)    #!#
      prineed=subtr_list(p.umiss, p1.umiss)               # those need private use (public ones already done)
      do_check_7(c, p, uprinpub, p1)                      # list use stmts which could be private instead of public
      do_check_8(c, p, pubneed, p1.supfl, p1)             # list needed public use stmts
      do_check_8(c, p, pubnpri, p1.supfl, p1, True)       # list need public but have private
      do_check_8(c, p, prineed, p.supfl, p)               # need private use stmts

      if c.o_writeuse:
        if c.o_local:                                     # remove "crossed" uses and unnecessary uses
##        do_modif(c, p, norm_list(p.supfl+uprinpub+pubnpri), pubneed+pubnpri, prineed+uprinpub, p1)
                                                          # ...do only the "crossed" ones for now
          do_modif(c, p, norm_list(uprinpub+pubnpri), pubneed+pubnpri, prineed+uprinpub, p1)
        else:
          do_write(c, p, p1.ipacks, subtr_list(p.ipacks, p1.ipacks))
  


def usage(c):
  print c.ckrvers, "usage:"
  print
  print "checkreq [options] [packages]"
  print "  options are:"
  print "  -h, --help             : print this information and quit."
  print "  -d, --detail           : write detailed checking results to stdout."
  print "  -i, --ignore= <level>  : in the exit code, ignore problems with severity"
  print "                           upto/including <level>, i.e. they get exit code 0."
  print "                           They are still reported as messages within checkreq."
  print "                           Nonzero exit code can result in Make failure and in"
  print "                           emails, depending on the settings in NICOS."
  print "  -n, --nicos            : prepend 'CHECKREQ--->' string to any regular output."
  print "  -l, --local            : use requirements file from working directory."
  print "                           Copy requirements over from /cmt if a local"
  print "                           requirements file does not exist."
  print "                           Filename is requirements_<package>_<release>."
  print "  -w, --writeuse         : write out use-statements generated from"
  print "                           required packages."
  print "                           For option -l, merge extra use statements"
  print "                           into requirements, and comment out unnecessary"
  print "                           use statements."
  print "  -x, --xversions        : do extended versions checking and inter-project"
  print "                           dependency checking, incl. runtime dependencies"
  print "                           (default)."
  print "  -v, --versions         : do limited versions checking."
  print "  -m, --mode= <mode>     : check all or only public requirements, against the"
  print "                           appropriate subset of (source/header) files for"
  print "                           <mode> = all, pub; do crosschecks between"
  print "                           public/private if <mode> = both."
  print "  -y, --python= <dir>,.. : check includes or imports in Python files against"
  print "                           use statements. Python files under ../<dir>/ are"
  print "                           checked. Comma-separate several <dir>."
  print "                           Default for <dir> is python (-y \"\" or --python=)."
  print "                           This option is off by default: NOTE that use stmts"
  print "                           are for CMT, not for stating runtime dependencies."
  print "  -p, --public           : same as -m both (default)."
  print "  -a, --all              : same as -m all - i.e. don't differentiate public/"
  print "                           private."
  print "  -u, --usecache= <file> : obsolete - ignored. Versions information is always"
  print "                           collected quickly, without caching it."
  print "  -r, --release= <prel>  : run on project/release <prel> with the given"
  print "             <package> ..  package-names, instead of on the current directory."
  print "                           E.g. 'AtlasCore/16.3.0 .' for all packages of"
  print "                           AtlasCore release 16.3.0."

def main():

  ch=checker()

  try:
    shortopts  = "i:m:u:r:y:dlwxvpahn"
    longopts   = ["ignore=", "mode=", "usecache=", "release=", "python=", "detail", "local", "writeuse", "xversions", "versions", \
                  "public", "all", "help", "nicos"]
    opts, args = getopt(argv[1:], shortopts, longopts)
  except GetoptError:
    usage(ch)
    ckrterm(ch, 1)

  for o, a in opts:
    if o in   ("-h", "-?", "--help"):
      usage(ch)
      exit(0)
    if o in   ("-d", "--detail"):
      ch.o_detail=True
    elif o in ("-i", "--ignore"):
      try:
        ch.o_ignore=int(a)
      except ValueError:
        usage(ch)
        ckrterm(ch, 1)
    elif o in ("-l", "--local"):
      ch.o_local=True
    elif o in ("-x", "--xversions"):
      ch.o_needcache=True
    elif o in ("-v", "--versions"):
      ch.o_needcache=False
    elif o in ("-m", "--mode"):
      if a not in ["all", "pub", "both"]:
        usage(ch)
        ckrterm(ch, 1)
      ch.o_public = a
    elif o in ("-y", "--python"):  ###:::###
      ch.o_python=True
      if a.strip() != "":
        ch.o_pydirs += a.strip().split(",")
    elif o in ("-p", "--public"):
      ch.o_public="both"
    elif o in ("-a", "--all"):
      ch.o_public="all"
    elif o in ("-n", "--nicos"):
      ch.o_nicos="CHECKREQ---> "
    elif o in ("-u", "--usecache"):
      ch.o_cacheuse = a
    elif o in ("-w", "--writeuse"):
      ch.o_writeuse=True
    elif o in ("-r", "--release"):
      ch.o_relident = a
      packstocheck = args

  if ch.o_writeuse:
    ch.o_needcache=True

  ch.prep()

  pwdir=path.abspath(".")
  if ch.o_relident == "":
    pj=package(ch, pwdir)
    do_checks(ch, pj)
    ckrexit(ch, pj)
  else:
    if ch.o_relident.startswith("/"):
      preldir=ch.o_relident
    else:
      preldir=ch.distarea + ch.o_relident
    for pack in packstocheck:
      detail(ch, "Working on package(s) " + pack + " for project/release " + ch.o_relident)
      if path.isdir(preldir + "/" + pack):
        iiold=path.abspath(".")
        if pack == ".":
          pac = ""
        else:
          pac = "/" + pack
        for iip in norm_list(cmtdirs(preldir + pac)):
          chdir(iip)
          pj=package(ch, iip)
          print "###########################################################\n"
          print "Package:", iip
          print "Version: " + do_cmt(ch, "show version") + "(" + pj.projname + ")\n"
          do_checks(ch, pj)
      else:
        info(ch, "Could not find " + pack + " in " + preldir)
    chdir(pwdir)


if __name__ == "__main__":
  main()



